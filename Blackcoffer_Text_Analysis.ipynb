{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "367a7c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the necessary libraries\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from newspaper import Article\n",
    "import os\n",
    "import nltk\n",
    "from nltk import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f69702ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114\n",
      "114\n",
      "[37.0, 38.0, 39.0, 40.0, 41.0]\n",
      "['https://insights.blackcoffer.com/ai-in-healthcare-to-improve-patient-outcomes/', 'https://insights.blackcoffer.com/what-if-the-creation-is-taking-over-the-creator/', 'https://insights.blackcoffer.com/what-jobs-will-robots-take-from-humans-in-the-future/', 'https://insights.blackcoffer.com/will-machine-replace-the-human-in-the-future-of-work/', 'https://insights.blackcoffer.com/will-ai-replace-us-or-work-with-us/']\n"
     ]
    }
   ],
   "source": [
    "#Read the URLs from the Input.xlsx and store in a list\n",
    "input_data = pd.read_excel('Input.xlsx')\n",
    "url_ids = input_data['URL_ID'].tolist()\n",
    "urls = input_data['URL'].tolist()\n",
    "\n",
    "# Check if all URL_IDs and URLs are read successfully\n",
    "print(len(url_ids))\n",
    "print(len(urls))\n",
    "print(url_ids[:5]) # Print first 5 URL_IDs to check if the list is correct\n",
    "print(urls[:5]) # Print first 5 URLs to check if the list is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9428de18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_article_text(url):\n",
    "    try:\n",
    "        article = Article(url)\n",
    "        article.download()\n",
    "        article.parse()\n",
    "        paragraphs = article.text.split('\\n')\n",
    "        article_text = '\\n'.join([p.strip() for p in paragraphs if p.strip() != ''])\n",
    "        article_title = article.title\n",
    "        return article_title, article_text\n",
    "    except Exception as e:\n",
    "        print(f\"Error in processing URL {url}: {e}\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0030eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in processing URL https://insights.blackcoffer.com/how-neural-networks-can-be-applied-in-various-areas-in-the-future/: Article `download()` failed with 404 Client Error: Not Found for url: https://insights.blackcoffer.com/how-neural-networks-can-be-applied-in-various-areas-in-the-future/ on URL https://insights.blackcoffer.com/how-neural-networks-can-be-applied-in-various-areas-in-the-future/\n",
      "Error in processing URL https://insights.blackcoffer.com/covid-19-environmental-impact-for-the-future/: Article `download()` failed with 404 Client Error: Not Found for url: https://insights.blackcoffer.com/covid-19-environmental-impact-for-the-future/ on URL https://insights.blackcoffer.com/covid-19-environmental-impact-for-the-future/\n",
      "Error in processing URL https://insights.blackcoffer.com/ensuring-growth-through-insurance-technology/: Article `download()` failed with 404 Client Error: Not Found for url: https://insights.blackcoffer.com/ensuring-growth-through-insurance-technology/ on URL https://insights.blackcoffer.com/ensuring-growth-through-insurance-technology/\n"
     ]
    }
   ],
   "source": [
    "for url_id, url in zip(url_ids, urls):\n",
    "    title, text = get_article_text(url)\n",
    "    if title is None or text is None:\n",
    "        continue\n",
    "    filename = str(int(url_id))\n",
    "    with open(filename + \".txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(title + \"\\n\" + text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bf3f571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list to store the rows of the dataframe\n",
    "rows = []\n",
    "\n",
    "# Iterate over the file names\n",
    "for file_name in os.listdir():\n",
    "    # Check if the file is a text file\n",
    "    if file_name.endswith(\".txt\"):\n",
    "        # Get the URL_ID from the file name by removing the '.txt' extension\n",
    "        url_id = file_name[:-4]\n",
    "        # Read the contents of the text file\n",
    "        if url_id in str(url_ids):\n",
    "            with open(file_name, \"r\", encoding=\"utf-8\") as f:\n",
    "                contents = f.read()\n",
    "            \n",
    "        # Split the contents into title and text\n",
    "            title, text = contents.split(\"\\n\", 1)\n",
    "        \n",
    "        # Append the row to the list of rows\n",
    "            rows.append([int(url_id), title, text])\n",
    "\n",
    "# Sort the list of rows based on the URL_ID column\n",
    "rows = sorted(rows, key=lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4c8ed7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe from the list of rows\n",
    "df = pd.DataFrame(rows, columns=['URL_ID', 'Title', 'Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45a3863f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"data.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "4cca77c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"data.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "3ca43ce0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>AI in healthcare to Improve Patient Outcomes</td>\n",
       "      <td>Introduction\\n“If anything kills over 10 milli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>What if the Creation is Taking Over the Creator?</td>\n",
       "      <td>Human minds, a fascination in itself carrying ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>What Jobs Will Robots Take From Humans in The ...</td>\n",
       "      <td>Introduction\\nAI is rapidly evolving in the em...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>Will Machine Replace The Human in the Future o...</td>\n",
       "      <td>“Anything that could give rise to smarter-than...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>Will AI Replace Us or Work With Us?</td>\n",
       "      <td>“Machine intelligence is the last invention th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>146</td>\n",
       "      <td>Blockchain for Payments</td>\n",
       "      <td>Reconciling with the financial realities of an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>147</td>\n",
       "      <td>The future of Investing</td>\n",
       "      <td>What Is an Investment?\\nAn investment is a res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>148</td>\n",
       "      <td>Big Data Analytics in Healthcare</td>\n",
       "      <td>Quality and affordable healthcare is a vision ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>149</td>\n",
       "      <td>Business Analytics In The Healthcare Industry</td>\n",
       "      <td>Analytics is a statistical scientific process ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>150</td>\n",
       "      <td>Challenges and Opportunities of Big Data in He...</td>\n",
       "      <td>Big Data\\nTo begin with I shall first like to ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>111 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     URL_ID                                              Title  \\\n",
       "0        37       AI in healthcare to Improve Patient Outcomes   \n",
       "1        38   What if the Creation is Taking Over the Creator?   \n",
       "2        39  What Jobs Will Robots Take From Humans in The ...   \n",
       "3        40  Will Machine Replace The Human in the Future o...   \n",
       "4        41                Will AI Replace Us or Work With Us?   \n",
       "..      ...                                                ...   \n",
       "106     146                            Blockchain for Payments   \n",
       "107     147                            The future of Investing   \n",
       "108     148                   Big Data Analytics in Healthcare   \n",
       "109     149      Business Analytics In The Healthcare Industry   \n",
       "110     150  Challenges and Opportunities of Big Data in He...   \n",
       "\n",
       "                                                  Text  \n",
       "0    Introduction\\n“If anything kills over 10 milli...  \n",
       "1    Human minds, a fascination in itself carrying ...  \n",
       "2    Introduction\\nAI is rapidly evolving in the em...  \n",
       "3    “Anything that could give rise to smarter-than...  \n",
       "4    “Machine intelligence is the last invention th...  \n",
       "..                                                 ...  \n",
       "106  Reconciling with the financial realities of an...  \n",
       "107  What Is an Investment?\\nAn investment is a res...  \n",
       "108  Quality and affordable healthcare is a vision ...  \n",
       "109  Analytics is a statistical scientific process ...  \n",
       "110  Big Data\\nTo begin with I shall first like to ...  \n",
       "\n",
       "[111 rows x 3 columns]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "e66f84fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Introduction\\n“If anything kills over 10 million people in the next few decades, it will be a highly infectious virus rather than a war. Not missiles but microbes.” Bill Gates’s remarks at a TED conference in 2014, right after the world had avoided the Ebola outbreak. When the new, unprecedented, invisible virus hit us, it met an overwhelmed and unprepared healthcare system and oblivious population. This public health emergency demonstrated our lack of scientific consideration and underlined the alarming need for robust innovations in our health and medical facilities. For the past few years, artificial intelligence has proven to be of tangible potential in the healthcare sectors, clinical practices, translational medical and biomedical research.\\nAfter the first case was detected in China on December 31st 2019, it was an AI program developed by BlueDot that alerted the world about the pandemic. It was quick to realise AI’s ability to analyse large chunks of data could help in detecting patterns and identifying and tracking the possible carriers of the virus.\\nMany tracing apps use AI to keep tabs on the people who have been infected and prevent the risk of cross-infection by using AI algorithms that can track patterns and extract some features to classify or categorise them.\\nSo how does AI do that?\\nIBM Watson, a sophisticated AI that works on cloud computing and natural language processing, has prominently contributed to the healthcare sector on a global level. Being a conversational AI, since 2013, Watson has helped in recommending treatments to patients suffering from cancer to ensure that they get the best treatment at optimum costs.\\nResearchers at Google Inc. showed that an AI system can be trained on thousands of images to achieve physician-level sensitivity.\\nBy identifying the molecular patterns associated with disease status and its subtypes, gene expression, and protein abundance levels, machine learning methods can detect fatal diseases like cancer at an early stage. Machine Learning (ML) techniques focus mainly on analyzing structured data, which can further help in clustering patients’ traits and infer the probability of disease outcomes. Since patient traits mainly include masses of data relating to age, gender, disease history, disease-specific data like diagnostic imaging and gene expressions, etc, ML can extract features from these data inputs by constructing data analytical algorithms.\\nML algorithms are either supervised or unsupervised. Unsupervised learning helps in extracting features and clustering similar features together that further leads to early detection of diseases. Clustering and principal component analysis enable grouping or clustering of similar traits together that are further used to maximize or minimize the similarity between the patients within or between the clusters. Since patient traits are recorded in multiple dimensions, such as genes, principal component analysis(PCA) creates the apparatus to reduce these dimensions which humans could have not done alone.\\nSupervised learning considers the outcomes of the subjects together with the traits, and further correlates the inputs with the outputs to predict the probability of getting a particular clinical event, expected value of a disease level or expected survival time, or risk of Down’s syndrome.\\nBiomarker panels that are mostly used to detect ovarian cancer, have outperformed the conventional statistical methods due to machine learning. In addition to this, the use of EHRs and Bayesian networks, which are a part of supervised machine learning algorithms, can predict clinical outcomes and mortality respectively.\\nUnstructured data such as clinical notes and texts are converted into machine-readable structured data with the help of natural language processing(NLP). NLP works with two components: text processing and classification. Text processing helps in identifying a series of disease-relevant keywords in clinical notes and then through classification are further categorized into normal and abnormal cases. Chest screening through ML and NLP has helped find abnormalities in the lungs and provide treatment to covid patients. Healthcare organizations use NLP-based chatbots to increase interactions with patients, keeping their mental health and wellness in check.\\nDeep learning is a modern extension of the classical neural network techniques which helps explore more complex non-linear patterns in data, using algorithms like convolution neural network, recurrent neural network, deep belief network, and deep neural network which enables more accurate clinical prediction. When it comes to genome interpretation, deep neural networks surpass the conventional methods of logistics regression and support vector machines.\\nSepsis Watch is an AI system trained in deep learning algorithms that holds the capability to analyze over 32 million data points to create a patient’s risk score and identify the early stages of sepsis.\\nAnother method known as the Learning-based Optimization of the Under Sampling Pattern( LOUPE) is based on integrating full resolution MRI scans with the convolutional neural network algorithm, which helps in creating more accurate reconstructions.\\nRobotic surgery is widely considered in most delicate surgeries like gynaecology and prostate surgery. Even after striking the right balance between human decisions and AI precision, robotic surgery reduces surgeon efficiency as they have to be manually operated through a console. Thus, autonomous robotic surgery is on the rise with inventions such as robotic silicon fingers that mimic the sense of touch that surgeons need to identify organs, cut tissues, etc., or robotic catheters that can navigate whether it is touching blood, tissue, or valve.\\nResearchers at Children’s National Hospital, Washington have already developed an AI called Smart Tissue Autonomous Robot (STAR), which performs a colon anastomosis on its own with the help of an ML-powered suturing tool, that automatically detects the patient’s breathing pattern to apply suture at the correct point.\\nAn image of STAR during surgery.\\nCloud computing in healthcare has helped in retrieving and sharing medical records safely with a reduction in maintenance costs. Through this technology doctors and various healthcare workers have access to detailed patient data that helps in speeding up analysis ultimately leading to better care in the form of more accurate information, medications, and therapies.\\nHow can It help in Biomedical research?\\nSince AI can analyze literature beyond readability, it can be used to concise biomedical research. With the help of ML algorithms and NLP, AI can accelerate screening and indexing of biomedical research, by ranking the literature of interest which allows researchers to formulate and test scientific hypotheses far more precisely and quickly. Taking it to the next level, AI systems like the computational modelling assistant (CMA) helps researchers to construct simulation models from the concepts they have in mind. Such innovations have majorly contributed to topics such as tumour suppressor mechanisms and protein-protein interaction information extraction.\\nAI as precision medicine\\nSince precision medicine focuses on healthcare interventions to individuals or groups of patients based on their profile, the various AI devices pave the way to practice it more efficiently. With the help of ML, complex algorithms like large datasets can be used to predict and create an optimal treatment strategy.\\nDeep learning and neural networks can be used to process data in healthcare apps and keep a close watch on the patient’s emotional state, food intake, or health monitoring.\\n“Omics” refers to the collective technologies that help in exploring the roles, relationships of various branches ending with the suffix “omics” such as genomics, proteomics, etc. Omics-based tests based on machine learning algorithms help find correlations and predict treatment responses, ultimately creating personalized treatments for individual patients.\\nHow it helps in psychology and neuro patients\\nFor psychologists studying creativity, AI is promising new classes of experiments that are developing data structures and programs and exploring novel theories on a new horizon. Studies show that AI can conduct therapy sessions, e-therapy sessions, and assessments autonomously, also assisting human practitioners before, during, or after sessions. The Detection and Computational Analysis of Psychological Signal project uses ML, computer vision, and NLP to analyze language, physical gestures, and social signals to identify cues for human distress. This ground-breaking technology assesses soldiers returning from combat and recognizes those who require further mental health support. In the future, it will combine data captured during face-to-face interviews with information on sleeping, eating, and online behaviours for a complete patient view.\\nStroke identification\\nStroke is another frequently occurring disease that affects more than 500 million people worldwide. Thrombus, in the vessel cerebral infarction is the major (about 85%) cause of stroke occurrence. In recent years, AI techniques have been used in numerous stroke-related studies as early detection and timely treatment along with efficient outcome prediction can help solve the problem. With AI at our disposal, large amounts of data with rich information, more complications and real-life clinical questions can be addressed in this arena. Currently, two ML algorithms- genetic fuzzy finite state machine and PCA were implemented to build a model building solution. These include a human activity recognition stage and a stroke onset detection stage. An alert stroke message is activated as soon as a movement significantly different from the normal pattern is recorded. ML methods have been applied to neuroimaging data to assist disease evaluation and predicting stroke treatment for the diagnosis.\\nPatient Monitoring\\nToday, the market for AI-based patient monitoring is impressive and monetarily enticing. It is evolving with artificial sensors, smart technologies and explores everything from brain-computer interfaces to nanorobotics. Companies with their smart-watches have engaged people to perform remote monitoring even when they are not “patients”. An obvious place to start is with wearable and embedded sensors, glucose monitors, pulse monitors, oximeters, and ECG monitors. With patient monitoring becoming crucial, AI finds numerous applications in chronic conditions, intensive care units, operating rooms, emergency rooms, and cardiac wards where timeless clinical decision-making can be measured in seconds. More advances have started to gain traction like smart prosthetics and implants. These play an impeccable role in patient management post-surgery or rehabilitation. Demographics, laboratory results and vital signs can also be used to predict cardiac arrest, transfer into the intensive care unit, or even death. In addition, an interpretable machine-learning model can assist anesthesiologists in predicting hypoxaemia events during surgery. This suggests that with deep-learning algorithms, raw patient-monitoring data could be better used to avoid information overload and alert overload while enabling more accurate clinical prediction and timely decision-making.\\nConclusion\\nConsidering the vast range of tasks that an AI can do, it is evident that it holds deep potential in improving patient outcomes to skyrocketing levels. Using sophisticated algorithms AI can bring a revolution in the healthcare sector. Even after facing challenges like whether the technology will be able to deliver the promises, ethical measures, training physicians to use it, standard regulations etc, the role of AI in transforming the clinical practices cannot be ignored. The biggest challenge is the integration of AI in daily practice. All of these can be overcome and within that period the technologies will mature making the system far more enhanced and effective.\\nBlackcoffer Insights 29: Sanskriti Sunderum and Aayushi Nauhwar, SRCC, Delhi University'"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Text\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc7bffc",
   "metadata": {},
   "source": [
    "## Text Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e3502c",
   "metadata": {},
   "source": [
    "#### Normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "b8aaed35",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df[\"Text\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "13fcdf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "d683de33",
   "metadata": {},
   "outputs": [],
   "source": [
    "re_special_char1 = r'\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "33ca1db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "re_special_char2 = r\"[^a-zA-Z|\\s]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "81d98e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = re.sub(re_special_char1, \"|\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "9fbe532d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = re.sub(re_special_char2, \"\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "931f9ed3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "introduction|if anything kills over  million people in the next few decades it will be a highly infectious virus rather than a war not missiles but microbes bill gatess remarks at a ted conference in  right after the world had avoided the ebola outbreak when the new unprecedented invisible virus hit us it met an overwhelmed and unprepared healthcare system and oblivious population this public health emergency demonstrated our lack of scientific consideration and underlined the alarming need for robust innovations in our health and medical facilities for the past few years artificial intelligence has proven to be of tangible potential in the healthcare sectors clinical practices translational medical and biomedical research|after the first case was detected in china on december st  it was an ai program developed by bluedot that alerted the world about the pandemic it was quick to realise ais ability to analyse large chunks of data could help in detecting patterns and identifying and tracking the possible carriers of the virus|many tracing apps use ai to keep tabs on the people who have been infected and prevent the risk of crossinfection by using ai algorithms that can track patterns and extract some features to classify or categorise them|so how does ai do that|ibm watson a sophisticated ai that works on cloud computing and natural language processing has prominently contributed to the healthcare sector on a global level being a conversational ai since  watson has helped in recommending treatments to patients suffering from cancer to ensure that they get the best treatment at optimum costs|researchers at google inc showed that an ai system can be trained on thousands of images to achieve physicianlevel sensitivity|by identifying the molecular patterns associated with disease status and its subtypes gene expression and protein abundance levels machine learning methods can detect fatal diseases like cancer at an early stage machine learning ml techniques focus mainly on analyzing structured data which can further help in clustering patients traits and infer the probability of disease outcomes since patient traits mainly include masses of data relating to age gender disease history diseasespecific data like diagnostic imaging and gene expressions etc ml can extract features from these data inputs by constructing data analytical algorithms|ml algorithms are either supervised or unsupervised unsupervised learning helps in extracting features and clustering similar features together that further leads to early detection of diseases clustering and principal component analysis enable grouping or clustering of similar traits together that are further used to maximize or minimize the similarity between the patients within or between the clusters since patient traits are recorded in multiple dimensions such as genes principal component analysispca creates the apparatus to reduce these dimensions which humans could have not done alone|supervised learning considers the outcomes of the subjects together with the traits and further correlates the inputs with the outputs to predict the probability of getting a particular clinical event expected value of a disease level or expected survival time or risk of downs syndrome|biomarker panels that are mostly used to detect ovarian cancer have outperformed the conventional statistical methods due to machine learning in addition to this the use of ehrs and bayesian networks which are a part of supervised machine learning algorithms can predict clinical outcomes and mortality respectively|unstructured data such as clinical notes and texts are converted into machinereadable structured data with the help of natural language processingnlp nlp works with two components text processing and classification text processing helps in identifying a series of diseaserelevant keywords in clinical notes and then through classification are further categorized into normal and abnormal cases chest screening through ml and nlp has helped find abnormalities in the lungs and provide treatment to covid patients healthcare organizations use nlpbased chatbots to increase interactions with patients keeping their mental health and wellness in check|deep learning is a modern extension of the classical neural network techniques which helps explore more complex nonlinear patterns in data using algorithms like convolution neural network recurrent neural network deep belief network and deep neural network which enables more accurate clinical prediction when it comes to genome interpretation deep neural networks surpass the conventional methods of logistics regression and support vector machines|sepsis watch is an ai system trained in deep learning algorithms that holds the capability to analyze over  million data points to create a patients risk score and identify the early stages of sepsis|another method known as the learningbased optimization of the under sampling pattern loupe is based on integrating full resolution mri scans with the convolutional neural network algorithm which helps in creating more accurate reconstructions|robotic surgery is widely considered in most delicate surgeries like gynaecology and prostate surgery even after striking the right balance between human decisions and ai precision robotic surgery reduces surgeon efficiency as they have to be manually operated through a console thus autonomous robotic surgery is on the rise with inventions such as robotic silicon fingers that mimic the sense of touch that surgeons need to identify organs cut tissues etc or robotic catheters that can navigate whether it is touching blood tissue or valve|researchers at childrens national hospital washington have already developed an ai called smart tissue autonomous robot star which performs a colon anastomosis on its own with the help of an mlpowered suturing tool that automatically detects the patients breathing pattern to apply suture at the correct point|an image of star during surgery|cloud computing in healthcare has helped in retrieving and sharing medical records safely with a reduction in maintenance costs through this technology doctors and various healthcare workers have access to detailed patient data that helps in speeding up analysis ultimately leading to better care in the form of more accurate information medications and therapies|how can it help in biomedical research|since ai can analyze literature beyond readability it can be used to concise biomedical research with the help of ml algorithms and nlp ai can accelerate screening and indexing of biomedical research by ranking the literature of interest which allows researchers to formulate and test scientific hypotheses far more precisely and quickly taking it to the next level ai systems like the computational modelling assistant cma helps researchers to construct simulation models from the concepts they have in mind such innovations have majorly contributed to topics such as tumour suppressor mechanisms and proteinprotein interaction information extraction|ai as precision medicine|since precision medicine focuses on healthcare interventions to individuals or groups of patients based on their profile the various ai devices pave the way to practice it more efficiently with the help of ml complex algorithms like large datasets can be used to predict and create an optimal treatment strategy|deep learning and neural networks can be used to process data in healthcare apps and keep a close watch on the patients emotional state food intake or health monitoring|omics refers to the collective technologies that help in exploring the roles relationships of various branches ending with the suffix omics such as genomics proteomics etc omicsbased tests based on machine learning algorithms help find correlations and predict treatment responses ultimately creating personalized treatments for individual patients|how it helps in psychology and neuro patients|for psychologists studying creativity ai is promising new classes of experiments that are developing data structures and programs and exploring novel theories on a new horizon studies show that ai can conduct therapy sessions etherapy sessions and assessments autonomously also assisting human practitioners before during or after sessions the detection and computational analysis of psychological signal project uses ml computer vision and nlp to analyze language physical gestures and social signals to identify cues for human distress this groundbreaking technology assesses soldiers returning from combat and recognizes those who require further mental health support in the future it will combine data captured during facetoface interviews with information on sleeping eating and online behaviours for a complete patient view|stroke identification|stroke is another frequently occurring disease that affects more than  million people worldwide thrombus in the vessel cerebral infarction is the major about  cause of stroke occurrence in recent years ai techniques have been used in numerous strokerelated studies as early detection and timely treatment along with efficient outcome prediction can help solve the problem with ai at our disposal large amounts of data with rich information more complications and reallife clinical questions can be addressed in this arena currently two ml algorithms genetic fuzzy finite state machine and pca were implemented to build a model building solution these include a human activity recognition stage and a stroke onset detection stage an alert stroke message is activated as soon as a movement significantly different from the normal pattern is recorded ml methods have been applied to neuroimaging data to assist disease evaluation and predicting stroke treatment for the diagnosis|patient monitoring|today the market for aibased patient monitoring is impressive and monetarily enticing it is evolving with artificial sensors smart technologies and explores everything from braincomputer interfaces to nanorobotics companies with their smartwatches have engaged people to perform remote monitoring even when they are not patients an obvious place to start is with wearable and embedded sensors glucose monitors pulse monitors oximeters and ecg monitors with patient monitoring becoming crucial ai finds numerous applications in chronic conditions intensive care units operating rooms emergency rooms and cardiac wards where timeless clinical decisionmaking can be measured in seconds more advances have started to gain traction like smart prosthetics and implants these play an impeccable role in patient management postsurgery or rehabilitation demographics laboratory results and vital signs can also be used to predict cardiac arrest transfer into the intensive care unit or even death in addition an interpretable machinelearning model can assist anesthesiologists in predicting hypoxaemia events during surgery this suggests that with deeplearning algorithms raw patientmonitoring data could be better used to avoid information overload and alert overload while enabling more accurate clinical prediction and timely decisionmaking|conclusion|considering the vast range of tasks that an ai can do it is evident that it holds deep potential in improving patient outcomes to skyrocketing levels using sophisticated algorithms ai can bring a revolution in the healthcare sector even after facing challenges like whether the technology will be able to deliver the promises ethical measures training physicians to use it standard regulations etc the role of ai in transforming the clinical practices cannot be ignored the biggest challenge is the integration of ai in daily practice all of these can be overcome and within that period the technologies will mature making the system far more enhanced and\n"
     ]
    }
   ],
   "source": [
    "\n",
    "text_list = text.split(\" \")\n",
    "text = \" \".join(text_list[:-11])\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5ff019",
   "metadata": {},
   "source": [
    "#### Stop Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "af1d69f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_stop_words(filename):\n",
    "    with open(filename, \"r\") as file:\n",
    "        stop_words = file.read().splitlines()\n",
    "    return [word.lower() for word in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "626e2b18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stop_words = []\n",
    "for filename in [\"StopWords_Auditor.txt\", \"StopWords_Currencies.txt\", \"StopWords_DatesandNumbers.txt\", \"StopWords_Generic.txt\", \"StopWords_GenericLong.txt\", \"StopWords_Geographic.txt\", \"StopWords_Names.txt\"]:\n",
    "    stop_words += read_stop_words(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "612c7251",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ernst',\n",
       " 'young',\n",
       " 'deloitte',\n",
       " 'touche',\n",
       " 'kpmg',\n",
       " 'pricewaterhousecoopers',\n",
       " 'pricewaterhouse',\n",
       " 'coopers',\n",
       " 'afghani  | afghanistan ',\n",
       " 'ariary | madagascar ',\n",
       " 'baht | thailand ',\n",
       " 'balboa | panama ',\n",
       " 'birr | ethiopia ',\n",
       " 'bolivar | venezuela ',\n",
       " 'boliviano  | bolivia ',\n",
       " 'cedi | ghana ',\n",
       " 'colon  | costa rica ',\n",
       " 'córdoba  | nicaragua ',\n",
       " 'dalasi | gambia ',\n",
       " 'denar | macedonia (former yug. rep.) ',\n",
       " 'dinar | algeria ',\n",
       " 'dirham  | morocco ',\n",
       " 'dobra | são tom and príncipe ',\n",
       " 'dong | vietnam ',\n",
       " 'dram | armenia ',\n",
       " 'escudo  | cape verde ',\n",
       " 'euro  | belgium ',\n",
       " 'florin | aruba ',\n",
       " 'forint | hungary ',\n",
       " 'gourde | haiti ',\n",
       " 'guarani | paraguay ',\n",
       " 'gulden | netherlands antilles ',\n",
       " 'hryvnia  | ukraine ',\n",
       " 'kina | papua new guinea ',\n",
       " 'kip | laos ',\n",
       " 'konvertibilna marka  | bosnia-herzegovina ',\n",
       " 'koruna  | czech republic ',\n",
       " 'krona | sweden ',\n",
       " 'krone | denmark ',\n",
       " 'kroon | estonia ',\n",
       " 'kuna | croatia ',\n",
       " 'kwacha | zambia ',\n",
       " 'kwanza | angola ',\n",
       " 'kyat | myanmar ',\n",
       " 'lari | georgia ',\n",
       " 'lats | latvia ',\n",
       " 'lek | albania ',\n",
       " 'lempira | honduras ',\n",
       " 'leone | sierra leone ',\n",
       " 'leu | romania ',\n",
       " 'lev | bulgaria ',\n",
       " 'lilangeni  | swaziland ',\n",
       " 'lira | lebanon ',\n",
       " 'litas | lithuania ',\n",
       " 'loti | lesotho ',\n",
       " 'manat | azerbaijan ',\n",
       " 'metical | mozambique ',\n",
       " 'naira | nigeria ',\n",
       " 'nakfa | eritrea ',\n",
       " 'new lira | turkey ',\n",
       " 'new sheqel  | israel ',\n",
       " 'ngultrum  | bhutan ',\n",
       " 'nuevo sol | peru ',\n",
       " 'ouguiya  | mauritania ',\n",
       " 'pataca | macau ',\n",
       " 'peso  | mexico ',\n",
       " 'pound  | egypt ',\n",
       " 'pula  | botswana ',\n",
       " 'quetzal | guatemala ',\n",
       " 'rand | south africa ',\n",
       " 'real  | brazil ',\n",
       " 'renminbi  | china ',\n",
       " 'rial | iran ',\n",
       " 'riel | cambodia ',\n",
       " 'ringgit | malaysia ',\n",
       " 'riyal | saudi arabia ',\n",
       " 'ruble | russia ',\n",
       " 'rufiyaa | maldives ',\n",
       " 'rupee  | india ',\n",
       " 'rupee  | pakistan ',\n",
       " 'rupiah  | indonesia ',\n",
       " 'shilling  | uganda ',\n",
       " 'som | uzbekistan ',\n",
       " 'somoni  | tajikistan ',\n",
       " 'special drawing rights  | international monetary fund ',\n",
       " 'taka | bangladesh ',\n",
       " 'tala | western samoa ',\n",
       " 'tenge | kazakhstan ',\n",
       " 'tugrik  | mongolia ',\n",
       " 'vatu | vanuatu ',\n",
       " 'won  | korea, south ',\n",
       " 'yen | japan ',\n",
       " 'zloty | poland ',\n",
       " 'hundred  | denominations',\n",
       " 'thousand',\n",
       " 'million',\n",
       " 'billion',\n",
       " 'trillion',\n",
       " 'date  | time related',\n",
       " 'annual',\n",
       " 'annually',\n",
       " 'annum',\n",
       " 'year',\n",
       " 'yearly',\n",
       " 'quarter',\n",
       " 'quarterly',\n",
       " 'qtr',\n",
       " 'month',\n",
       " 'monthly',\n",
       " 'week',\n",
       " 'weekly',\n",
       " 'day',\n",
       " 'daily',\n",
       " 'january  | calendar',\n",
       " 'february',\n",
       " 'march',\n",
       " 'april',\n",
       " 'may',\n",
       " 'june',\n",
       " 'july',\n",
       " 'august',\n",
       " 'september',\n",
       " 'october',\n",
       " 'november',\n",
       " 'december',\n",
       " 'jan',\n",
       " 'feb',\n",
       " 'mar',\n",
       " 'apr',\n",
       " 'may',\n",
       " 'jun',\n",
       " 'jul',\n",
       " 'aug',\n",
       " 'sep',\n",
       " 'sept',\n",
       " 'oct',\n",
       " 'nov',\n",
       " 'dec',\n",
       " 'monday',\n",
       " 'tuesday',\n",
       " 'wednesday',\n",
       " 'thursday',\n",
       " 'friday',\n",
       " 'saturday',\n",
       " 'sunday',\n",
       " 'one  | numbers',\n",
       " 'two',\n",
       " 'three',\n",
       " 'four',\n",
       " 'five',\n",
       " 'six',\n",
       " 'seven',\n",
       " 'eight',\n",
       " 'nine',\n",
       " 'ten',\n",
       " 'eleven',\n",
       " 'twelve',\n",
       " 'thirteen',\n",
       " 'fourteen',\n",
       " 'fifteen',\n",
       " 'sixteen',\n",
       " 'seventeen',\n",
       " 'eighteen',\n",
       " 'nineteen',\n",
       " 'twenty',\n",
       " 'thirty',\n",
       " 'forty',\n",
       " 'fifty',\n",
       " 'sixty',\n",
       " 'seventy',\n",
       " 'eighty',\n",
       " 'ninety',\n",
       " 'first',\n",
       " 'second',\n",
       " 'third',\n",
       " 'fourth',\n",
       " 'fifth',\n",
       " 'sixth',\n",
       " 'seventh',\n",
       " 'eighth',\n",
       " 'ninth',\n",
       " 'tenth',\n",
       " 'i  | roman numerals',\n",
       " 'ii',\n",
       " 'iii',\n",
       " 'iv',\n",
       " 'v',\n",
       " 'vi',\n",
       " 'vii',\n",
       " 'viii',\n",
       " 'ix',\n",
       " 'x',\n",
       " 'xi',\n",
       " 'xii',\n",
       " 'xiii',\n",
       " 'xiv',\n",
       " 'xv',\n",
       " 'xvi',\n",
       " 'xvii',\n",
       " 'xviii',\n",
       " 'xix',\n",
       " 'xx',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'all',\n",
       " 'am',\n",
       " 'among',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'did',\n",
       " 'do',\n",
       " 'does',\n",
       " 'doing',\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'has',\n",
       " 'have',\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'it',\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'me',\n",
       " 'more',\n",
       " 'most',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 'same',\n",
       " 'she',\n",
       " 'should',\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 'than',\n",
       " 'that',\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 'very',\n",
       " 'was',\n",
       " 'we',\n",
       " 'were',\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'with',\n",
       " 'you',\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'a',\n",
       " \"a's\",\n",
       " 'able',\n",
       " 'about',\n",
       " 'above',\n",
       " 'according',\n",
       " 'accordingly',\n",
       " 'across',\n",
       " 'actually',\n",
       " 'after',\n",
       " 'afterwards',\n",
       " 'again',\n",
       " 'against',\n",
       " \"ain't\",\n",
       " 'all',\n",
       " 'allow',\n",
       " 'allows',\n",
       " 'almost',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'already',\n",
       " 'also',\n",
       " 'although',\n",
       " 'always',\n",
       " 'am',\n",
       " 'among',\n",
       " 'amongst',\n",
       " 'an',\n",
       " 'and',\n",
       " 'another',\n",
       " 'any',\n",
       " 'anybody',\n",
       " 'anyhow',\n",
       " 'anyone',\n",
       " 'anything',\n",
       " 'anyway',\n",
       " 'anyways',\n",
       " 'anywhere',\n",
       " 'apart',\n",
       " 'appear',\n",
       " 'appreciate',\n",
       " 'appropriate',\n",
       " 'are',\n",
       " \"aren't\",\n",
       " 'around',\n",
       " 'as',\n",
       " 'aside',\n",
       " 'ask',\n",
       " 'asking',\n",
       " 'associated',\n",
       " 'at',\n",
       " 'available',\n",
       " 'away',\n",
       " 'awfully',\n",
       " 'b',\n",
       " 'be',\n",
       " 'became',\n",
       " 'because',\n",
       " 'become',\n",
       " 'becomes',\n",
       " 'becoming',\n",
       " 'been',\n",
       " 'before',\n",
       " 'beforehand',\n",
       " 'behind',\n",
       " 'being',\n",
       " 'believe',\n",
       " 'below',\n",
       " 'beside',\n",
       " 'besides',\n",
       " 'best',\n",
       " 'better',\n",
       " 'between',\n",
       " 'beyond',\n",
       " 'both',\n",
       " 'brief',\n",
       " 'but',\n",
       " 'by',\n",
       " 'c',\n",
       " \"c'mon\",\n",
       " \"c's\",\n",
       " 'came',\n",
       " 'can',\n",
       " \"can't\",\n",
       " 'cannot',\n",
       " 'cant',\n",
       " 'cause',\n",
       " 'causes',\n",
       " 'certain',\n",
       " 'certainly',\n",
       " 'changes',\n",
       " 'clearly',\n",
       " 'co',\n",
       " 'com',\n",
       " 'come',\n",
       " 'comes',\n",
       " 'concerning',\n",
       " 'consequently',\n",
       " 'consider',\n",
       " 'considering',\n",
       " 'contain',\n",
       " 'containing',\n",
       " 'contains',\n",
       " 'corresponding',\n",
       " 'could',\n",
       " \"couldn't\",\n",
       " 'course',\n",
       " 'currently',\n",
       " 'd',\n",
       " 'definitely',\n",
       " 'described',\n",
       " 'despite',\n",
       " 'did',\n",
       " \"didn't\",\n",
       " 'different',\n",
       " 'do',\n",
       " 'does',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " \"don't\",\n",
       " 'done',\n",
       " 'down',\n",
       " 'downwards',\n",
       " 'during',\n",
       " 'e',\n",
       " 'each',\n",
       " 'edu',\n",
       " 'eg',\n",
       " 'eight',\n",
       " 'either',\n",
       " 'else',\n",
       " 'elsewhere',\n",
       " 'enough',\n",
       " 'entirely',\n",
       " 'especially',\n",
       " 'et',\n",
       " 'etc',\n",
       " 'even',\n",
       " 'ever',\n",
       " 'every',\n",
       " 'everybody',\n",
       " 'everyone',\n",
       " 'everything',\n",
       " 'everywhere',\n",
       " 'ex',\n",
       " 'exactly',\n",
       " 'example',\n",
       " 'except',\n",
       " 'f',\n",
       " 'far',\n",
       " 'few',\n",
       " 'fifth',\n",
       " 'first',\n",
       " 'five',\n",
       " 'followed',\n",
       " 'following',\n",
       " 'follows',\n",
       " 'for',\n",
       " 'former',\n",
       " 'formerly',\n",
       " 'forth',\n",
       " 'four',\n",
       " 'from',\n",
       " 'further',\n",
       " 'furthermore',\n",
       " 'g',\n",
       " 'get',\n",
       " 'gets',\n",
       " 'getting',\n",
       " 'given',\n",
       " 'gives',\n",
       " 'go',\n",
       " 'goes',\n",
       " 'going',\n",
       " 'gone',\n",
       " 'got',\n",
       " 'gotten',\n",
       " 'greetings',\n",
       " 'h',\n",
       " 'had',\n",
       " \"hadn't\",\n",
       " 'happens',\n",
       " 'hardly',\n",
       " 'has',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " \"he's\",\n",
       " 'hello',\n",
       " 'help',\n",
       " 'hence',\n",
       " 'her',\n",
       " 'here',\n",
       " \"here's\",\n",
       " 'hereafter',\n",
       " 'hereby',\n",
       " 'herein',\n",
       " 'hereupon',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'hi',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'hither',\n",
       " 'hopefully',\n",
       " 'how',\n",
       " 'howbeit',\n",
       " 'however',\n",
       " 'i',\n",
       " \"i'd\",\n",
       " \"i'll\",\n",
       " \"i'm\",\n",
       " \"i've\",\n",
       " 'ie',\n",
       " 'if',\n",
       " 'ignored',\n",
       " 'immediate',\n",
       " 'in',\n",
       " 'inasmuch',\n",
       " 'inc',\n",
       " 'indeed',\n",
       " 'indicate',\n",
       " 'indicated',\n",
       " 'indicates',\n",
       " 'inner',\n",
       " 'insofar',\n",
       " 'instead',\n",
       " 'into',\n",
       " 'inward',\n",
       " 'is',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it'd\",\n",
       " \"it'll\",\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'j',\n",
       " 'just',\n",
       " 'k',\n",
       " 'keep',\n",
       " 'keeps',\n",
       " 'kept',\n",
       " 'know',\n",
       " 'knows',\n",
       " 'known',\n",
       " 'l',\n",
       " 'last',\n",
       " 'lately',\n",
       " 'later',\n",
       " 'latter',\n",
       " 'latterly',\n",
       " 'least',\n",
       " 'less',\n",
       " 'lest',\n",
       " 'let',\n",
       " \"let's\",\n",
       " 'like',\n",
       " 'liked',\n",
       " 'likely',\n",
       " 'little',\n",
       " 'look',\n",
       " 'looking',\n",
       " 'looks',\n",
       " 'ltd',\n",
       " 'm',\n",
       " 'mainly',\n",
       " 'many',\n",
       " 'may',\n",
       " 'maybe',\n",
       " 'me',\n",
       " 'mean',\n",
       " 'meanwhile',\n",
       " 'merely',\n",
       " 'might',\n",
       " 'more',\n",
       " 'moreover',\n",
       " 'most',\n",
       " 'mostly',\n",
       " 'much',\n",
       " 'must',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'n',\n",
       " 'name',\n",
       " 'namely',\n",
       " 'nd',\n",
       " 'near',\n",
       " 'nearly',\n",
       " 'necessary',\n",
       " 'need',\n",
       " 'needs',\n",
       " 'neither',\n",
       " 'never',\n",
       " 'nevertheless',\n",
       " 'new',\n",
       " 'next',\n",
       " 'nine',\n",
       " 'no',\n",
       " 'nobody',\n",
       " 'non',\n",
       " 'none',\n",
       " 'noone',\n",
       " 'nor',\n",
       " 'normally',\n",
       " 'not',\n",
       " 'nothing',\n",
       " 'novel',\n",
       " 'now',\n",
       " 'nowhere',\n",
       " 'o',\n",
       " 'obviously',\n",
       " 'of',\n",
       " 'off',\n",
       " 'often',\n",
       " 'oh',\n",
       " 'ok',\n",
       " 'okay',\n",
       " 'old',\n",
       " 'on',\n",
       " 'once',\n",
       " 'one',\n",
       " 'ones',\n",
       " 'only',\n",
       " 'onto',\n",
       " 'or',\n",
       " 'other',\n",
       " 'others',\n",
       " 'otherwise',\n",
       " 'ought',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'outside',\n",
       " 'over',\n",
       " 'overall',\n",
       " 'own',\n",
       " 'p',\n",
       " 'particular',\n",
       " 'particularly',\n",
       " 'per',\n",
       " 'perhaps',\n",
       " 'placed',\n",
       " 'please',\n",
       " 'plus',\n",
       " 'possible',\n",
       " 'presumably',\n",
       " 'probably',\n",
       " 'provides',\n",
       " 'q',\n",
       " 'que',\n",
       " 'quite',\n",
       " 'qv',\n",
       " 'r',\n",
       " 'rather',\n",
       " 'rd',\n",
       " 're',\n",
       " 'really',\n",
       " 'reasonably',\n",
       " 'regarding',\n",
       " 'regardless',\n",
       " 'regards',\n",
       " 'relatively',\n",
       " 'respectively',\n",
       " 'right',\n",
       " 's',\n",
       " 'said',\n",
       " 'same',\n",
       " 'saw',\n",
       " 'say',\n",
       " 'saying',\n",
       " 'says',\n",
       " 'second',\n",
       " 'secondly',\n",
       " 'see',\n",
       " 'seeing',\n",
       " 'seem',\n",
       " 'seemed',\n",
       " 'seeming',\n",
       " 'seems',\n",
       " 'seen',\n",
       " 'self',\n",
       " 'selves',\n",
       " 'sensible',\n",
       " 'sent',\n",
       " 'serious',\n",
       " 'seriously',\n",
       " 'seven',\n",
       " 'several',\n",
       " 'shall',\n",
       " 'she',\n",
       " 'should',\n",
       " \"shouldn't\",\n",
       " 'since',\n",
       " 'six',\n",
       " 'so',\n",
       " 'some',\n",
       " 'somebody',\n",
       " 'somehow',\n",
       " 'someone',\n",
       " 'something',\n",
       " 'sometime',\n",
       " 'sometimes',\n",
       " 'somewhat',\n",
       " 'somewhere',\n",
       " 'soon',\n",
       " 'sorry',\n",
       " 'specified',\n",
       " 'specify',\n",
       " 'specifying',\n",
       " 'still',\n",
       " 'sub',\n",
       " 'such',\n",
       " 'sup',\n",
       " 'sure',\n",
       " 't',\n",
       " \"t's\",\n",
       " 'take',\n",
       " 'taken',\n",
       " 'tell',\n",
       " 'tends',\n",
       " 'th',\n",
       " 'than',\n",
       " 'thank',\n",
       " 'thanks',\n",
       " 'thanx',\n",
       " 'that',\n",
       " \"that's\",\n",
       " 'thats',\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'thence',\n",
       " 'there',\n",
       " \"there's\",\n",
       " 'thereafter',\n",
       " 'thereby',\n",
       " 'therefore',\n",
       " 'therein',\n",
       " 'theres',\n",
       " 'thereupon',\n",
       " 'these',\n",
       " 'they',\n",
       " \"they'd\",\n",
       " \"they'll\",\n",
       " \"they're\",\n",
       " \"they've\",\n",
       " 'think',\n",
       " 'third',\n",
       " 'this',\n",
       " 'thorough',\n",
       " 'thoroughly',\n",
       " 'those',\n",
       " 'though',\n",
       " 'three',\n",
       " 'through',\n",
       " 'throughout',\n",
       " 'thru',\n",
       " 'thus',\n",
       " 'to',\n",
       " 'together',\n",
       " 'too',\n",
       " 'took',\n",
       " 'toward',\n",
       " 'towards',\n",
       " 'tried',\n",
       " 'tries',\n",
       " 'truly',\n",
       " 'try',\n",
       " 'trying',\n",
       " 'twice',\n",
       " 'two',\n",
       " 'u',\n",
       " 'un',\n",
       " 'under',\n",
       " 'unfortunately',\n",
       " 'unless',\n",
       " 'unlikely',\n",
       " 'until',\n",
       " 'unto',\n",
       " 'up',\n",
       " 'upon',\n",
       " 'us',\n",
       " 'use',\n",
       " 'used',\n",
       " 'useful',\n",
       " 'uses',\n",
       " 'using',\n",
       " 'usually',\n",
       " 'uucp',\n",
       " 'v',\n",
       " 'value',\n",
       " 'various',\n",
       " 'very',\n",
       " 'via',\n",
       " 'viz',\n",
       " 'vs',\n",
       " 'w',\n",
       " 'want',\n",
       " 'wants',\n",
       " 'was',\n",
       " \"wasn't\",\n",
       " 'way',\n",
       " 'we',\n",
       " \"we'd\",\n",
       " \"we'll\",\n",
       " \"we're\",\n",
       " \"we've\",\n",
       " 'welcome',\n",
       " 'well',\n",
       " 'went',\n",
       " 'were',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " \"what's\",\n",
       " 'whatever',\n",
       " 'when',\n",
       " 'whence',\n",
       " 'whenever',\n",
       " 'where',\n",
       " \"where's\",\n",
       " 'whereafter',\n",
       " 'whereas',\n",
       " 'whereby',\n",
       " 'wherein',\n",
       " 'whereupon',\n",
       " 'wherever',\n",
       " 'whether',\n",
       " 'which',\n",
       " 'while',\n",
       " 'whither',\n",
       " 'who',\n",
       " \"who's\",\n",
       " 'whoever',\n",
       " 'whole',\n",
       " 'whom',\n",
       " 'whose',\n",
       " 'why',\n",
       " 'will',\n",
       " 'willing',\n",
       " 'wish',\n",
       " 'with',\n",
       " 'within',\n",
       " 'without',\n",
       " \"won't\",\n",
       " 'wonder',\n",
       " 'would',\n",
       " 'would',\n",
       " \"wouldn't\",\n",
       " 'x',\n",
       " 'y',\n",
       " 'yes',\n",
       " 'yet',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'z',\n",
       " 'zero',\n",
       " 'united  | geographic',\n",
       " 'state',\n",
       " 'north',\n",
       " 'south',\n",
       " 'east',\n",
       " 'northeast',\n",
       " 'northwest',\n",
       " 'southeast',\n",
       " 'southwest',\n",
       " 'west',\n",
       " 'ocean',\n",
       " 'sea',\n",
       " 'lake',\n",
       " 'river',\n",
       " 'creek',\n",
       " 'gulf',\n",
       " 'mountain',\n",
       " 'street',\n",
       " 'boulevard',\n",
       " 'blvd',\n",
       " 'parkway',\n",
       " 'city',\n",
       " 'county',\n",
       " 'country',\n",
       " 'pacific',\n",
       " 'atlantic',\n",
       " 'indian',\n",
       " 'mediterranean',\n",
       " 'commonwealth',\n",
       " 'america',\n",
       " 'american',\n",
       " 'york  | cities',\n",
       " 'chicago',\n",
       " 'las',\n",
       " 'vegas',\n",
       " 'los',\n",
       " 'angeles',\n",
       " 'milwaukee',\n",
       " 'sunnyvale',\n",
       " 'fremont',\n",
       " 'cincinnati',\n",
       " 'philadelphia',\n",
       " 'miami',\n",
       " 'dallas',\n",
       " 'fort',\n",
       " 'boston',\n",
       " 'houston',\n",
       " 'washington',\n",
       " 'atlanta',\n",
       " 'detroit',\n",
       " 'san',\n",
       " 'fransico',\n",
       " 'phoenix',\n",
       " 'seattle',\n",
       " 'diego',\n",
       " 'minneapolis',\n",
       " 'memphis',\n",
       " 'denver',\n",
       " 'st',\n",
       " 'louis',\n",
       " 'pittsburgh',\n",
       " 'manhattan',\n",
       " 'hollywood',\n",
       " 'columbus',\n",
       " 'indianapolis',\n",
       " 'mumbai',\n",
       " 'karachi',\n",
       " 'ontario',\n",
       " 'toronto',\n",
       " 'cambridge',\n",
       " 'delhi',\n",
       " 'sao',\n",
       " 'paulo',\n",
       " 'shanghai',\n",
       " 'moscow',\n",
       " 'seoul',\n",
       " 'istanbul',\n",
       " 'tokyo',\n",
       " 'jakarta',\n",
       " 'beijing',\n",
       " 'london',\n",
       " 'luxembourg',\n",
       " 'singapore',\n",
       " 'republic  | countries',\n",
       " 'china',\n",
       " 'india',\n",
       " 'indonesia',\n",
       " 'brazil',\n",
       " 'brazilian',\n",
       " 'pakistan',\n",
       " 'bangladesh',\n",
       " 'russia',\n",
       " 'nigeria',\n",
       " 'nova',\n",
       " 'scotia',\n",
       " 'japan',\n",
       " 'malaysia',\n",
       " 'mexico',\n",
       " 'mexican',\n",
       " 'philippines',\n",
       " 'vietnam',\n",
       " 'germany',\n",
       " 'france',\n",
       " 'korea',\n",
       " 'spain',\n",
       " 'argentina',\n",
       " ...]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "a7f02460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['introduction|if', 'anything', 'kills', 'over', 'million', 'people', 'in', 'the', 'next', 'few', 'decades', 'it', 'will', 'be', 'a', 'highly', 'infectious', 'virus', 'rather', 'than', 'a', 'war', 'not', 'missiles', 'but', 'microbes', 'bill', 'gatess', 'remarks', 'at', 'a', 'ted', 'conference', 'in', 'right', 'after', 'the', 'world', 'had', 'avoided', 'the', 'ebola', 'outbreak', 'when', 'the', 'new', 'unprecedented', 'invisible', 'virus', 'hit', 'us', 'it', 'met', 'an', 'overwhelmed', 'and', 'unprepared', 'healthcare', 'system', 'and', 'oblivious', 'population', 'this', 'public', 'health', 'emergency', 'demonstrated', 'our', 'lack', 'of', 'scientific', 'consideration', 'and', 'underlined', 'the', 'alarming', 'need', 'for', 'robust', 'innovations', 'in', 'our', 'health', 'and', 'medical', 'facilities', 'for', 'the', 'past', 'few', 'years', 'artificial', 'intelligence', 'has', 'proven', 'to', 'be', 'of', 'tangible', 'potential', 'in', 'the', 'healthcare', 'sectors', 'clinical', 'practices', 'translational', 'medical', 'and', 'biomedical', 'research|after', 'the', 'first', 'case', 'was', 'detected', 'in', 'china', 'on', 'december', 'st', 'it', 'was', 'an', 'ai', 'program', 'developed', 'by', 'bluedot', 'that', 'alerted', 'the', 'world', 'about', 'the', 'pandemic', 'it', 'was', 'quick', 'to', 'realise', 'ais', 'ability', 'to', 'analyse', 'large', 'chunks', 'of', 'data', 'could', 'help', 'in', 'detecting', 'patterns', 'and', 'identifying', 'and', 'tracking', 'the', 'possible', 'carriers', 'of', 'the', 'virus|many', 'tracing', 'apps', 'use', 'ai', 'to', 'keep', 'tabs', 'on', 'the', 'people', 'who', 'have', 'been', 'infected', 'and', 'prevent', 'the', 'risk', 'of', 'crossinfection', 'by', 'using', 'ai', 'algorithms', 'that', 'can', 'track', 'patterns', 'and', 'extract', 'some', 'features', 'to', 'classify', 'or', 'categorise', 'them|so', 'how', 'does', 'ai', 'do', 'that|ibm', 'watson', 'a', 'sophisticated', 'ai', 'that', 'works', 'on', 'cloud', 'computing', 'and', 'natural', 'language', 'processing', 'has', 'prominently', 'contributed', 'to', 'the', 'healthcare', 'sector', 'on', 'a', 'global', 'level', 'being', 'a', 'conversational', 'ai', 'since', 'watson', 'has', 'helped', 'in', 'recommending', 'treatments', 'to', 'patients', 'suffering', 'from', 'cancer', 'to', 'ensure', 'that', 'they', 'get', 'the', 'best', 'treatment', 'at', 'optimum', 'costs|researchers', 'at', 'google', 'inc', 'showed', 'that', 'an', 'ai', 'system', 'can', 'be', 'trained', 'on', 'thousands', 'of', 'images', 'to', 'achieve', 'physicianlevel', 'sensitivity|by', 'identifying', 'the', 'molecular', 'patterns', 'associated', 'with', 'disease', 'status', 'and', 'its', 'subtypes', 'gene', 'expression', 'and', 'protein', 'abundance', 'levels', 'machine', 'learning', 'methods', 'can', 'detect', 'fatal', 'diseases', 'like', 'cancer', 'at', 'an', 'early', 'stage', 'machine', 'learning', 'ml', 'techniques', 'focus', 'mainly', 'on', 'analyzing', 'structured', 'data', 'which', 'can', 'further', 'help', 'in', 'clustering', 'patients', 'traits', 'and', 'infer', 'the', 'probability', 'of', 'disease', 'outcomes', 'since', 'patient', 'traits', 'mainly', 'include', 'masses', 'of', 'data', 'relating', 'to', 'age', 'gender', 'disease', 'history', 'diseasespecific', 'data', 'like', 'diagnostic', 'imaging', 'and', 'gene', 'expressions', 'etc', 'ml', 'can', 'extract', 'features', 'from', 'these', 'data', 'inputs', 'by', 'constructing', 'data', 'analytical', 'algorithms|ml', 'algorithms', 'are', 'either', 'supervised', 'or', 'unsupervised', 'unsupervised', 'learning', 'helps', 'in', 'extracting', 'features', 'and', 'clustering', 'similar', 'features', 'together', 'that', 'further', 'leads', 'to', 'early', 'detection', 'of', 'diseases', 'clustering', 'and', 'principal', 'component', 'analysis', 'enable', 'grouping', 'or', 'clustering', 'of', 'similar', 'traits', 'together', 'that', 'are', 'further', 'used', 'to', 'maximize', 'or', 'minimize', 'the', 'similarity', 'between', 'the', 'patients', 'within', 'or', 'between', 'the', 'clusters', 'since', 'patient', 'traits', 'are', 'recorded', 'in', 'multiple', 'dimensions', 'such', 'as', 'genes', 'principal', 'component', 'analysispca', 'creates', 'the', 'apparatus', 'to', 'reduce', 'these', 'dimensions', 'which', 'humans', 'could', 'have', 'not', 'done', 'alone|supervised', 'learning', 'considers', 'the', 'outcomes', 'of', 'the', 'subjects', 'together', 'with', 'the', 'traits', 'and', 'further', 'correlates', 'the', 'inputs', 'with', 'the', 'outputs', 'to', 'predict', 'the', 'probability', 'of', 'getting', 'a', 'particular', 'clinical', 'event', 'expected', 'value', 'of', 'a', 'disease', 'level', 'or', 'expected', 'survival', 'time', 'or', 'risk', 'of', 'downs', 'syndrome|biomarker', 'panels', 'that', 'are', 'mostly', 'used', 'to', 'detect', 'ovarian', 'cancer', 'have', 'outperformed', 'the', 'conventional', 'statistical', 'methods', 'due', 'to', 'machine', 'learning', 'in', 'addition', 'to', 'this', 'the', 'use', 'of', 'ehrs', 'and', 'bayesian', 'networks', 'which', 'are', 'a', 'part', 'of', 'supervised', 'machine', 'learning', 'algorithms', 'can', 'predict', 'clinical', 'outcomes', 'and', 'mortality', 'respectively|unstructured', 'data', 'such', 'as', 'clinical', 'notes', 'and', 'texts', 'are', 'converted', 'into', 'machinereadable', 'structured', 'data', 'with', 'the', 'help', 'of', 'natural', 'language', 'processingnlp', 'nlp', 'works', 'with', 'two', 'components', 'text', 'processing', 'and', 'classification', 'text', 'processing', 'helps', 'in', 'identifying', 'a', 'series', 'of', 'diseaserelevant', 'keywords', 'in', 'clinical', 'notes', 'and', 'then', 'through', 'classification', 'are', 'further', 'categorized', 'into', 'normal', 'and', 'abnormal', 'cases', 'chest', 'screening', 'through', 'ml', 'and', 'nlp', 'has', 'helped', 'find', 'abnormalities', 'in', 'the', 'lungs', 'and', 'provide', 'treatment', 'to', 'covid', 'patients', 'healthcare', 'organizations', 'use', 'nlpbased', 'chatbots', 'to', 'increase', 'interactions', 'with', 'patients', 'keeping', 'their', 'mental', 'health', 'and', 'wellness', 'in', 'check|deep', 'learning', 'is', 'a', 'modern', 'extension', 'of', 'the', 'classical', 'neural', 'network', 'techniques', 'which', 'helps', 'explore', 'more', 'complex', 'nonlinear', 'patterns', 'in', 'data', 'using', 'algorithms', 'like', 'convolution', 'neural', 'network', 'recurrent', 'neural', 'network', 'deep', 'belief', 'network', 'and', 'deep', 'neural', 'network', 'which', 'enables', 'more', 'accurate', 'clinical', 'prediction', 'when', 'it', 'comes', 'to', 'genome', 'interpretation', 'deep', 'neural', 'networks', 'surpass', 'the', 'conventional', 'methods', 'of', 'logistics', 'regression', 'and', 'support', 'vector', 'machines|sepsis', 'watch', 'is', 'an', 'ai', 'system', 'trained', 'in', 'deep', 'learning', 'algorithms', 'that', 'holds', 'the', 'capability', 'to', 'analyze', 'over', 'million', 'data', 'points', 'to', 'create', 'a', 'patients', 'risk', 'score', 'and', 'identify', 'the', 'early', 'stages', 'of', 'sepsis|another', 'method', 'known', 'as', 'the', 'learningbased', 'optimization', 'of', 'the', 'under', 'sampling', 'pattern', 'loupe', 'is', 'based', 'on', 'integrating', 'full', 'resolution', 'mri', 'scans', 'with', 'the', 'convolutional', 'neural', 'network', 'algorithm', 'which', 'helps', 'in', 'creating', 'more', 'accurate', 'reconstructions|robotic', 'surgery', 'is', 'widely', 'considered', 'in', 'most', 'delicate', 'surgeries', 'like', 'gynaecology', 'and', 'prostate', 'surgery', 'even', 'after', 'striking', 'the', 'right', 'balance', 'between', 'human', 'decisions', 'and', 'ai', 'precision', 'robotic', 'surgery', 'reduces', 'surgeon', 'efficiency', 'as', 'they', 'have', 'to', 'be', 'manually', 'operated', 'through', 'a', 'console', 'thus', 'autonomous', 'robotic', 'surgery', 'is', 'on', 'the', 'rise', 'with', 'inventions', 'such', 'as', 'robotic', 'silicon', 'fingers', 'that', 'mimic', 'the', 'sense', 'of', 'touch', 'that', 'surgeons', 'need', 'to', 'identify', 'organs', 'cut', 'tissues', 'etc', 'or', 'robotic', 'catheters', 'that', 'can', 'navigate', 'whether', 'it', 'is', 'touching', 'blood', 'tissue', 'or', 'valve|researchers', 'at', 'childrens', 'national', 'hospital', 'washington', 'have', 'already', 'developed', 'an', 'ai', 'called', 'smart', 'tissue', 'autonomous', 'robot', 'star', 'which', 'performs', 'a', 'colon', 'anastomosis', 'on', 'its', 'own', 'with', 'the', 'help', 'of', 'an', 'mlpowered', 'suturing', 'tool', 'that', 'automatically', 'detects', 'the', 'patients', 'breathing', 'pattern', 'to', 'apply', 'suture', 'at', 'the', 'correct', 'point|an', 'image', 'of', 'star', 'during', 'surgery|cloud', 'computing', 'in', 'healthcare', 'has', 'helped', 'in', 'retrieving', 'and', 'sharing', 'medical', 'records', 'safely', 'with', 'a', 'reduction', 'in', 'maintenance', 'costs', 'through', 'this', 'technology', 'doctors', 'and', 'various', 'healthcare', 'workers', 'have', 'access', 'to', 'detailed', 'patient', 'data', 'that', 'helps', 'in', 'speeding', 'up', 'analysis', 'ultimately', 'leading', 'to', 'better', 'care', 'in', 'the', 'form', 'of', 'more', 'accurate', 'information', 'medications', 'and', 'therapies|how', 'can', 'it', 'help', 'in', 'biomedical', 'research|since', 'ai', 'can', 'analyze', 'literature', 'beyond', 'readability', 'it', 'can', 'be', 'used', 'to', 'concise', 'biomedical', 'research', 'with', 'the', 'help', 'of', 'ml', 'algorithms', 'and', 'nlp', 'ai', 'can', 'accelerate', 'screening', 'and', 'indexing', 'of', 'biomedical', 'research', 'by', 'ranking', 'the', 'literature', 'of', 'interest', 'which', 'allows', 'researchers', 'to', 'formulate', 'and', 'test', 'scientific', 'hypotheses', 'far', 'more', 'precisely', 'and', 'quickly', 'taking', 'it', 'to', 'the', 'next', 'level', 'ai', 'systems', 'like', 'the', 'computational', 'modelling', 'assistant', 'cma', 'helps', 'researchers', 'to', 'construct', 'simulation', 'models', 'from', 'the', 'concepts', 'they', 'have', 'in', 'mind', 'such', 'innovations', 'have', 'majorly', 'contributed', 'to', 'topics', 'such', 'as', 'tumour', 'suppressor', 'mechanisms', 'and', 'proteinprotein', 'interaction', 'information', 'extraction|ai', 'as', 'precision', 'medicine|since', 'precision', 'medicine', 'focuses', 'on', 'healthcare', 'interventions', 'to', 'individuals', 'or', 'groups', 'of', 'patients', 'based', 'on', 'their', 'profile', 'the', 'various', 'ai', 'devices', 'pave', 'the', 'way', 'to', 'practice', 'it', 'more', 'efficiently', 'with', 'the', 'help', 'of', 'ml', 'complex', 'algorithms', 'like', 'large', 'datasets', 'can', 'be', 'used', 'to', 'predict', 'and', 'create', 'an', 'optimal', 'treatment', 'strategy|deep', 'learning', 'and', 'neural', 'networks', 'can', 'be', 'used', 'to', 'process', 'data', 'in', 'healthcare', 'apps', 'and', 'keep', 'a', 'close', 'watch', 'on', 'the', 'patients', 'emotional', 'state', 'food', 'intake', 'or', 'health', 'monitoring|omics', 'refers', 'to', 'the', 'collective', 'technologies', 'that', 'help', 'in', 'exploring', 'the', 'roles', 'relationships', 'of', 'various', 'branches', 'ending', 'with', 'the', 'suffix', 'omics', 'such', 'as', 'genomics', 'proteomics', 'etc', 'omicsbased', 'tests', 'based', 'on', 'machine', 'learning', 'algorithms', 'help', 'find', 'correlations', 'and', 'predict', 'treatment', 'responses', 'ultimately', 'creating', 'personalized', 'treatments', 'for', 'individual', 'patients|how', 'it', 'helps', 'in', 'psychology', 'and', 'neuro', 'patients|for', 'psychologists', 'studying', 'creativity', 'ai', 'is', 'promising', 'new', 'classes', 'of', 'experiments', 'that', 'are', 'developing', 'data', 'structures', 'and', 'programs', 'and', 'exploring', 'novel', 'theories', 'on', 'a', 'new', 'horizon', 'studies', 'show', 'that', 'ai', 'can', 'conduct', 'therapy', 'sessions', 'etherapy', 'sessions', 'and', 'assessments', 'autonomously', 'also', 'assisting', 'human', 'practitioners', 'before', 'during', 'or', 'after', 'sessions', 'the', 'detection', 'and', 'computational', 'analysis', 'of', 'psychological', 'signal', 'project', 'uses', 'ml', 'computer', 'vision', 'and', 'nlp', 'to', 'analyze', 'language', 'physical', 'gestures', 'and', 'social', 'signals', 'to', 'identify', 'cues', 'for', 'human', 'distress', 'this', 'groundbreaking', 'technology', 'assesses', 'soldiers', 'returning', 'from', 'combat', 'and', 'recognizes', 'those', 'who', 'require', 'further', 'mental', 'health', 'support', 'in', 'the', 'future', 'it', 'will', 'combine', 'data', 'captured', 'during', 'facetoface', 'interviews', 'with', 'information', 'on', 'sleeping', 'eating', 'and', 'online', 'behaviours', 'for', 'a', 'complete', 'patient', 'view|stroke', 'identification|stroke', 'is', 'another', 'frequently', 'occurring', 'disease', 'that', 'affects', 'more', 'than', 'million', 'people', 'worldwide', 'thrombus', 'in', 'the', 'vessel', 'cerebral', 'infarction', 'is', 'the', 'major', 'about', 'cause', 'of', 'stroke', 'occurrence', 'in', 'recent', 'years', 'ai', 'techniques', 'have', 'been', 'used', 'in', 'numerous', 'strokerelated', 'studies', 'as', 'early', 'detection', 'and', 'timely', 'treatment', 'along', 'with', 'efficient', 'outcome', 'prediction', 'can', 'help', 'solve', 'the', 'problem', 'with', 'ai', 'at', 'our', 'disposal', 'large', 'amounts', 'of', 'data', 'with', 'rich', 'information', 'more', 'complications', 'and', 'reallife', 'clinical', 'questions', 'can', 'be', 'addressed', 'in', 'this', 'arena', 'currently', 'two', 'ml', 'algorithms', 'genetic', 'fuzzy', 'finite', 'state', 'machine', 'and', 'pca', 'were', 'implemented', 'to', 'build', 'a', 'model', 'building', 'solution', 'these', 'include', 'a', 'human', 'activity', 'recognition', 'stage', 'and', 'a', 'stroke', 'onset', 'detection', 'stage', 'an', 'alert', 'stroke', 'message', 'is', 'activated', 'as', 'soon', 'as', 'a', 'movement', 'significantly', 'different', 'from', 'the', 'normal', 'pattern', 'is', 'recorded', 'ml', 'methods', 'have', 'been', 'applied', 'to', 'neuroimaging', 'data', 'to', 'assist', 'disease', 'evaluation', 'and', 'predicting', 'stroke', 'treatment', 'for', 'the', 'diagnosis|patient', 'monitoring|today', 'the', 'market', 'for', 'aibased', 'patient', 'monitoring', 'is', 'impressive', 'and', 'monetarily', 'enticing', 'it', 'is', 'evolving', 'with', 'artificial', 'sensors', 'smart', 'technologies', 'and', 'explores', 'everything', 'from', 'braincomputer', 'interfaces', 'to', 'nanorobotics', 'companies', 'with', 'their', 'smartwatches', 'have', 'engaged', 'people', 'to', 'perform', 'remote', 'monitoring', 'even', 'when', 'they', 'are', 'not', 'patients', 'an', 'obvious', 'place', 'to', 'start', 'is', 'with', 'wearable', 'and', 'embedded', 'sensors', 'glucose', 'monitors', 'pulse', 'monitors', 'oximeters', 'and', 'ecg', 'monitors', 'with', 'patient', 'monitoring', 'becoming', 'crucial', 'ai', 'finds', 'numerous', 'applications', 'in', 'chronic', 'conditions', 'intensive', 'care', 'units', 'operating', 'rooms', 'emergency', 'rooms', 'and', 'cardiac', 'wards', 'where', 'timeless', 'clinical', 'decisionmaking', 'can', 'be', 'measured', 'in', 'seconds', 'more', 'advances', 'have', 'started', 'to', 'gain', 'traction', 'like', 'smart', 'prosthetics', 'and', 'implants', 'these', 'play', 'an', 'impeccable', 'role', 'in', 'patient', 'management', 'postsurgery', 'or', 'rehabilitation', 'demographics', 'laboratory', 'results', 'and', 'vital', 'signs', 'can', 'also', 'be', 'used', 'to', 'predict', 'cardiac', 'arrest', 'transfer', 'into', 'the', 'intensive', 'care', 'unit', 'or', 'even', 'death', 'in', 'addition', 'an', 'interpretable', 'machinelearning', 'model', 'can', 'assist', 'anesthesiologists', 'in', 'predicting', 'hypoxaemia', 'events', 'during', 'surgery', 'this', 'suggests', 'that', 'with', 'deeplearning', 'algorithms', 'raw', 'patientmonitoring', 'data', 'could', 'be', 'better', 'used', 'to', 'avoid', 'information', 'overload', 'and', 'alert', 'overload', 'while', 'enabling', 'more', 'accurate', 'clinical', 'prediction', 'and', 'timely', 'decisionmaking|conclusion|considering', 'the', 'vast', 'range', 'of', 'tasks', 'that', 'an', 'ai', 'can', 'do', 'it', 'is', 'evident', 'that', 'it', 'holds', 'deep', 'potential', 'in', 'improving', 'patient', 'outcomes', 'to', 'skyrocketing', 'levels', 'using', 'sophisticated', 'algorithms', 'ai', 'can', 'bring', 'a', 'revolution', 'in', 'the', 'healthcare', 'sector', 'even', 'after', 'facing', 'challenges', 'like', 'whether', 'the', 'technology', 'will', 'be', 'able', 'to', 'deliver', 'the', 'promises', 'ethical', 'measures', 'training', 'physicians', 'to', 'use', 'it', 'standard', 'regulations', 'etc', 'the', 'role', 'of', 'ai', 'in', 'transforming', 'the', 'clinical', 'practices', 'cannot', 'be', 'ignored', 'the', 'biggest', 'challenge', 'is', 'the', 'integration', 'of', 'ai', 'in', 'daily', 'practice', 'all', 'of', 'these', 'can', 'be', 'overcome', 'and', 'within', 'that', 'period', 'the', 'technologies', 'will', 'mature', 'making', 'the', 'system', 'far', 'more', 'enhanced', 'and']\n"
     ]
    }
   ],
   "source": [
    "text = text.split()\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "2daf1aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [word for word in text if word not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "de39324a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocessing(text):\n",
    "    #Replace \\n at end of sentence with |\n",
    "    text = re.sub(re_special_char1, '|', text)\n",
    "    #Normalizing the case\n",
    "    text = text.lower()\n",
    "    #Remove the special characters\n",
    "    text = re.sub(re_special_char2, \"\", text)\n",
    "    text_list = text.split(\" \")\n",
    "    text = \" \".join(text_list[:-11])\n",
    "    #Word Tokenization\n",
    "    text = text.split()\n",
    "    #Stopword removal \n",
    "    text = [word for word in text if word not in stop_words]\n",
    "    #Joining text\n",
    "    text = \" \".join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "b6cb40d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Text\"]= df[\"Text\"].apply(text_preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "029d5760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>AI in healthcare to Improve Patient Outcomes</td>\n",
       "      <td>introduction|if kills people decades highly in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>What if the Creation is Taking Over the Creator?</td>\n",
       "      <td>human minds fascination carrying potential tin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>What Jobs Will Robots Take From Humans in The ...</td>\n",
       "      <td>introduction|ai rapidly evolving employment se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>Will Machine Replace The Human in the Future o...</td>\n",
       "      <td>give rise smarterthanhuman intelligence form a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>Will AI Replace Us or Work With Us?</td>\n",
       "      <td>machine intelligence invention humanity make|n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>146</td>\n",
       "      <td>Blockchain for Payments</td>\n",
       "      <td>reconciling financial realities mba education ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>147</td>\n",
       "      <td>The future of Investing</td>\n",
       "      <td>investment|an investment resource thing procur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>148</td>\n",
       "      <td>Big Data Analytics in Healthcare</td>\n",
       "      <td>quality affordable healthcare vision governmen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>149</td>\n",
       "      <td>Business Analytics In The Healthcare Industry</td>\n",
       "      <td>analytics statistical scientific process disco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>150</td>\n",
       "      <td>Challenges and Opportunities of Big Data in He...</td>\n",
       "      <td>big data|to begin explain big data important l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>111 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     URL_ID                                              Title  \\\n",
       "0        37       AI in healthcare to Improve Patient Outcomes   \n",
       "1        38   What if the Creation is Taking Over the Creator?   \n",
       "2        39  What Jobs Will Robots Take From Humans in The ...   \n",
       "3        40  Will Machine Replace The Human in the Future o...   \n",
       "4        41                Will AI Replace Us or Work With Us?   \n",
       "..      ...                                                ...   \n",
       "106     146                            Blockchain for Payments   \n",
       "107     147                            The future of Investing   \n",
       "108     148                   Big Data Analytics in Healthcare   \n",
       "109     149      Business Analytics In The Healthcare Industry   \n",
       "110     150  Challenges and Opportunities of Big Data in He...   \n",
       "\n",
       "                                                  Text  \n",
       "0    introduction|if kills people decades highly in...  \n",
       "1    human minds fascination carrying potential tin...  \n",
       "2    introduction|ai rapidly evolving employment se...  \n",
       "3    give rise smarterthanhuman intelligence form a...  \n",
       "4    machine intelligence invention humanity make|n...  \n",
       "..                                                 ...  \n",
       "106  reconciling financial realities mba education ...  \n",
       "107  investment|an investment resource thing procur...  \n",
       "108  quality affordable healthcare vision governmen...  \n",
       "109  analytics statistical scientific process disco...  \n",
       "110  big data|to begin explain big data important l...  \n",
       "\n",
       "[111 rows x 3 columns]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e83cc2",
   "metadata": {},
   "source": [
    "#### Master Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "cf14512e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the two files that contain the positive and negative words, and create two lists to store the words\n",
    "def read_words(filename):\n",
    "    with open(filename, \"r\") as file:\n",
    "        words = file.read().splitlines()\n",
    "    return [word.lower() for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "1d17492f",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_words = read_words(\"positive-words.txt\")\n",
    "negative_words = read_words(\"negative-words.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d3a0ff",
   "metadata": {},
   "source": [
    "### Extracting Derived Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "ef21df7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute the positive and negative scores of each text in your data\n",
    "def compute_scores(text):\n",
    "    positive_score = 0\n",
    "    negative_score = 0\n",
    "    for word in text.split():\n",
    "        if word in positive_words:\n",
    "            positive_score += 1\n",
    "        if word in negative_words:\n",
    "            negative_score += -1\n",
    "    return {'positive_score': positive_score, 'negative_score': negative_score * -1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "e954429c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['positive_score', 'negative_score']] = df['Text'].apply(compute_scores).apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "d9000d5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Text</th>\n",
       "      <th>positive_score</th>\n",
       "      <th>negative_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>AI in healthcare to Improve Patient Outcomes</td>\n",
       "      <td>introduction|if kills people decades highly in...</td>\n",
       "      <td>58</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>What if the Creation is Taking Over the Creator?</td>\n",
       "      <td>human minds fascination carrying potential tin...</td>\n",
       "      <td>55</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>What Jobs Will Robots Take From Humans in The ...</td>\n",
       "      <td>introduction|ai rapidly evolving employment se...</td>\n",
       "      <td>64</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>Will Machine Replace The Human in the Future o...</td>\n",
       "      <td>give rise smarterthanhuman intelligence form a...</td>\n",
       "      <td>59</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>Will AI Replace Us or Work With Us?</td>\n",
       "      <td>machine intelligence invention humanity make|n...</td>\n",
       "      <td>54</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>146</td>\n",
       "      <td>Blockchain for Payments</td>\n",
       "      <td>reconciling financial realities mba education ...</td>\n",
       "      <td>20</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>147</td>\n",
       "      <td>The future of Investing</td>\n",
       "      <td>investment|an investment resource thing procur...</td>\n",
       "      <td>33</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>148</td>\n",
       "      <td>Big Data Analytics in Healthcare</td>\n",
       "      <td>quality affordable healthcare vision governmen...</td>\n",
       "      <td>26</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>149</td>\n",
       "      <td>Business Analytics In The Healthcare Industry</td>\n",
       "      <td>analytics statistical scientific process disco...</td>\n",
       "      <td>35</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>150</td>\n",
       "      <td>Challenges and Opportunities of Big Data in He...</td>\n",
       "      <td>big data|to begin explain big data important l...</td>\n",
       "      <td>30</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>111 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     URL_ID                                              Title  \\\n",
       "0        37       AI in healthcare to Improve Patient Outcomes   \n",
       "1        38   What if the Creation is Taking Over the Creator?   \n",
       "2        39  What Jobs Will Robots Take From Humans in The ...   \n",
       "3        40  Will Machine Replace The Human in the Future o...   \n",
       "4        41                Will AI Replace Us or Work With Us?   \n",
       "..      ...                                                ...   \n",
       "106     146                            Blockchain for Payments   \n",
       "107     147                            The future of Investing   \n",
       "108     148                   Big Data Analytics in Healthcare   \n",
       "109     149      Business Analytics In The Healthcare Industry   \n",
       "110     150  Challenges and Opportunities of Big Data in He...   \n",
       "\n",
       "                                                  Text  positive_score  \\\n",
       "0    introduction|if kills people decades highly in...              58   \n",
       "1    human minds fascination carrying potential tin...              55   \n",
       "2    introduction|ai rapidly evolving employment se...              64   \n",
       "3    give rise smarterthanhuman intelligence form a...              59   \n",
       "4    machine intelligence invention humanity make|n...              54   \n",
       "..                                                 ...             ...   \n",
       "106  reconciling financial realities mba education ...              20   \n",
       "107  investment|an investment resource thing procur...              33   \n",
       "108  quality affordable healthcare vision governmen...              26   \n",
       "109  analytics statistical scientific process disco...              35   \n",
       "110  big data|to begin explain big data important l...              30   \n",
       "\n",
       "     negative_score  \n",
       "0                30  \n",
       "1                35  \n",
       "2                34  \n",
       "3                21  \n",
       "4                24  \n",
       "..              ...  \n",
       "106              25  \n",
       "107              10  \n",
       "108              41  \n",
       "109               4  \n",
       "110              36  \n",
       "\n",
       "[111 rows x 5 columns]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "37d5d42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_polarity_score(positive_score, negative_score):\n",
    "    polarity_score = (positive_score - negative_score) / ((positive_score + negative_score) + 0.000001)\n",
    "    return polarity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "6df98320",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['polarity_score'] = df.apply(lambda x: compute_polarity_score(x['positive_score'], x['negative_score']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "c5c5d0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_subjectivity_score(text, positive_score, negative_score):\n",
    "    total_words = len(text.split())\n",
    "    subjectivity_score = (positive_score + negative_score) / (total_words + 0.000001)\n",
    "    return subjectivity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "4fe11eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "subjectivity_scores = df['Text'].apply(lambda x: compute_subjectivity_score(x, compute_scores(x)['positive_score'], compute_scores(x)['negative_score']))\n",
    "df['subjectivity_score'] = subjectivity_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "e7941b7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Text</th>\n",
       "      <th>positive_score</th>\n",
       "      <th>negative_score</th>\n",
       "      <th>polarity_score</th>\n",
       "      <th>subjectivity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>AI in healthcare to Improve Patient Outcomes</td>\n",
       "      <td>introduction|if kills people decades highly in...</td>\n",
       "      <td>58</td>\n",
       "      <td>30</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.095032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>What if the Creation is Taking Over the Creator?</td>\n",
       "      <td>human minds fascination carrying potential tin...</td>\n",
       "      <td>55</td>\n",
       "      <td>35</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.165746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>What Jobs Will Robots Take From Humans in The ...</td>\n",
       "      <td>introduction|ai rapidly evolving employment se...</td>\n",
       "      <td>64</td>\n",
       "      <td>34</td>\n",
       "      <td>0.306122</td>\n",
       "      <td>0.122653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>Will Machine Replace The Human in the Future o...</td>\n",
       "      <td>give rise smarterthanhuman intelligence form a...</td>\n",
       "      <td>59</td>\n",
       "      <td>21</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.132890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>Will AI Replace Us or Work With Us?</td>\n",
       "      <td>machine intelligence invention humanity make|n...</td>\n",
       "      <td>54</td>\n",
       "      <td>24</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.105978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>146</td>\n",
       "      <td>Blockchain for Payments</td>\n",
       "      <td>reconciling financial realities mba education ...</td>\n",
       "      <td>20</td>\n",
       "      <td>25</td>\n",
       "      <td>-0.111111</td>\n",
       "      <td>0.110024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>147</td>\n",
       "      <td>The future of Investing</td>\n",
       "      <td>investment|an investment resource thing procur...</td>\n",
       "      <td>33</td>\n",
       "      <td>10</td>\n",
       "      <td>0.534884</td>\n",
       "      <td>0.063988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>148</td>\n",
       "      <td>Big Data Analytics in Healthcare</td>\n",
       "      <td>quality affordable healthcare vision governmen...</td>\n",
       "      <td>26</td>\n",
       "      <td>41</td>\n",
       "      <td>-0.223881</td>\n",
       "      <td>0.120939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>149</td>\n",
       "      <td>Business Analytics In The Healthcare Industry</td>\n",
       "      <td>analytics statistical scientific process disco...</td>\n",
       "      <td>35</td>\n",
       "      <td>4</td>\n",
       "      <td>0.794872</td>\n",
       "      <td>0.107143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>150</td>\n",
       "      <td>Challenges and Opportunities of Big Data in He...</td>\n",
       "      <td>big data|to begin explain big data important l...</td>\n",
       "      <td>30</td>\n",
       "      <td>36</td>\n",
       "      <td>-0.090909</td>\n",
       "      <td>0.138655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>111 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     URL_ID                                              Title  \\\n",
       "0        37       AI in healthcare to Improve Patient Outcomes   \n",
       "1        38   What if the Creation is Taking Over the Creator?   \n",
       "2        39  What Jobs Will Robots Take From Humans in The ...   \n",
       "3        40  Will Machine Replace The Human in the Future o...   \n",
       "4        41                Will AI Replace Us or Work With Us?   \n",
       "..      ...                                                ...   \n",
       "106     146                            Blockchain for Payments   \n",
       "107     147                            The future of Investing   \n",
       "108     148                   Big Data Analytics in Healthcare   \n",
       "109     149      Business Analytics In The Healthcare Industry   \n",
       "110     150  Challenges and Opportunities of Big Data in He...   \n",
       "\n",
       "                                                  Text  positive_score  \\\n",
       "0    introduction|if kills people decades highly in...              58   \n",
       "1    human minds fascination carrying potential tin...              55   \n",
       "2    introduction|ai rapidly evolving employment se...              64   \n",
       "3    give rise smarterthanhuman intelligence form a...              59   \n",
       "4    machine intelligence invention humanity make|n...              54   \n",
       "..                                                 ...             ...   \n",
       "106  reconciling financial realities mba education ...              20   \n",
       "107  investment|an investment resource thing procur...              33   \n",
       "108  quality affordable healthcare vision governmen...              26   \n",
       "109  analytics statistical scientific process disco...              35   \n",
       "110  big data|to begin explain big data important l...              30   \n",
       "\n",
       "     negative_score  polarity_score  subjectivity_score  \n",
       "0                30        0.318182            0.095032  \n",
       "1                35        0.222222            0.165746  \n",
       "2                34        0.306122            0.122653  \n",
       "3                21        0.475000            0.132890  \n",
       "4                24        0.384615            0.105978  \n",
       "..              ...             ...                 ...  \n",
       "106              25       -0.111111            0.110024  \n",
       "107              10        0.534884            0.063988  \n",
       "108              41       -0.223881            0.120939  \n",
       "109               4        0.794872            0.107143  \n",
       "110              36       -0.090909            0.138655  \n",
       "\n",
       "[111 rows x 7 columns]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eeb0e37",
   "metadata": {},
   "source": [
    "### Complex Word Count & Analysis of Readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "4ad36ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "187a3fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_syllables(word):\n",
    "    vowels = 'aeiouAEIOU'\n",
    "    syllable_count = 0\n",
    "    word = word.lower()\n",
    "    if word[0] in vowels:\n",
    "        syllable_count += 1\n",
    "    for index in range(1, len(word)):\n",
    "        if word[index] in vowels and word[index - 1] not in vowels:\n",
    "            syllable_count += 1\n",
    "    if word.endswith('e'):\n",
    "        syllable_count -= 1\n",
    "    if syllable_count == 0:\n",
    "        syllable_count += 1\n",
    "    return syllable_count\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "faf1e4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_readability(text):\n",
    "    avg_sentence_length = 0\n",
    "    complex_words = 0\n",
    "    sentences = text.split(\"|\")\n",
    "    total_words = len(nltk.word_tokenize(text))\n",
    "    avg_sentence_length = total_words / len(sentences)\n",
    "    words = nltk.word_tokenize(text)\n",
    "    for word in words:\n",
    "        syllable_count = count_syllables(word)\n",
    "        if syllable_count > 2:\n",
    "            complex_words += 1\n",
    "    \n",
    "    percentage_of_complex_words = complex_words / total_words\n",
    "    fog_index = 0.4 * (avg_sentence_length + percentage_of_complex_words)\n",
    "    \n",
    "    return {'Avg Sentence Length': avg_sentence_length, 'Percentage of Complex words': percentage_of_complex_words, 'Fog Index': fog_index}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "382c6691",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Avg Sentence Length', 'Percentage of Complex words', 'Fog Index']] = df.apply(lambda x: compute_readability(x['Text']), axis=1, result_type=\"expand\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0f89c6",
   "metadata": {},
   "source": [
    "### Average Number of Words Per Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "bc708cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_words_per_sentence(text):\n",
    "    sentences = text.split(\"|\")\n",
    "    words = len(text.split())\n",
    "    avg_words = words/len(sentences)\n",
    "    return avg_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "34950c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Avg Words Per Sentence'] = df['Text'].apply(lambda x: avg_words_per_sentence(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158747f1",
   "metadata": {},
   "source": [
    "### Complex Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "62607b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_complex_words(text):\n",
    "    complex_words = 0\n",
    "    words = nltk.word_tokenize(text)\n",
    "    for word in words:\n",
    "        syllable_count = count_syllables(word)\n",
    "        if syllable_count > 2:\n",
    "            complex_words += 1\n",
    "    return complex_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "534e9249",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Complex word count'] = df['Text'].apply(lambda x: count_complex_words(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "4569c161",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Text</th>\n",
       "      <th>positive_score</th>\n",
       "      <th>negative_score</th>\n",
       "      <th>polarity_score</th>\n",
       "      <th>subjectivity_score</th>\n",
       "      <th>Avg Sentence Length</th>\n",
       "      <th>Percentage of Complex words</th>\n",
       "      <th>Fog Index</th>\n",
       "      <th>Avg Words Per Sentence</th>\n",
       "      <th>Complex word count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>AI in healthcare to Improve Patient Outcomes</td>\n",
       "      <td>introduction|if kills people decades highly in...</td>\n",
       "      <td>58</td>\n",
       "      <td>30</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.095032</td>\n",
       "      <td>28.060606</td>\n",
       "      <td>0.451404</td>\n",
       "      <td>11.404804</td>\n",
       "      <td>28.060606</td>\n",
       "      <td>418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>What if the Creation is Taking Over the Creator?</td>\n",
       "      <td>human minds fascination carrying potential tin...</td>\n",
       "      <td>55</td>\n",
       "      <td>35</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.165746</td>\n",
       "      <td>36.200000</td>\n",
       "      <td>0.395948</td>\n",
       "      <td>14.638379</td>\n",
       "      <td>36.200000</td>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>What Jobs Will Robots Take From Humans in The ...</td>\n",
       "      <td>introduction|ai rapidly evolving employment se...</td>\n",
       "      <td>64</td>\n",
       "      <td>34</td>\n",
       "      <td>0.306122</td>\n",
       "      <td>0.122653</td>\n",
       "      <td>28.535714</td>\n",
       "      <td>0.468085</td>\n",
       "      <td>11.601520</td>\n",
       "      <td>28.535714</td>\n",
       "      <td>374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>Will Machine Replace The Human in the Future o...</td>\n",
       "      <td>give rise smarterthanhuman intelligence form a...</td>\n",
       "      <td>59</td>\n",
       "      <td>21</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.132890</td>\n",
       "      <td>17.705882</td>\n",
       "      <td>0.377076</td>\n",
       "      <td>7.233184</td>\n",
       "      <td>17.705882</td>\n",
       "      <td>227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>Will AI Replace Us or Work With Us?</td>\n",
       "      <td>machine intelligence invention humanity make|n...</td>\n",
       "      <td>54</td>\n",
       "      <td>24</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.105978</td>\n",
       "      <td>19.368421</td>\n",
       "      <td>0.421196</td>\n",
       "      <td>7.915847</td>\n",
       "      <td>19.368421</td>\n",
       "      <td>310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>146</td>\n",
       "      <td>Blockchain for Payments</td>\n",
       "      <td>reconciling financial realities mba education ...</td>\n",
       "      <td>20</td>\n",
       "      <td>25</td>\n",
       "      <td>-0.111111</td>\n",
       "      <td>0.110024</td>\n",
       "      <td>22.722222</td>\n",
       "      <td>0.408313</td>\n",
       "      <td>9.252214</td>\n",
       "      <td>22.722222</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>147</td>\n",
       "      <td>The future of Investing</td>\n",
       "      <td>investment|an investment resource thing procur...</td>\n",
       "      <td>33</td>\n",
       "      <td>10</td>\n",
       "      <td>0.534884</td>\n",
       "      <td>0.063988</td>\n",
       "      <td>19.764706</td>\n",
       "      <td>0.403274</td>\n",
       "      <td>8.067192</td>\n",
       "      <td>19.764706</td>\n",
       "      <td>271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>148</td>\n",
       "      <td>Big Data Analytics in Healthcare</td>\n",
       "      <td>quality affordable healthcare vision governmen...</td>\n",
       "      <td>26</td>\n",
       "      <td>41</td>\n",
       "      <td>-0.223881</td>\n",
       "      <td>0.120939</td>\n",
       "      <td>25.181818</td>\n",
       "      <td>0.393502</td>\n",
       "      <td>10.230128</td>\n",
       "      <td>25.181818</td>\n",
       "      <td>218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>149</td>\n",
       "      <td>Business Analytics In The Healthcare Industry</td>\n",
       "      <td>analytics statistical scientific process disco...</td>\n",
       "      <td>35</td>\n",
       "      <td>4</td>\n",
       "      <td>0.794872</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>21.411765</td>\n",
       "      <td>0.530220</td>\n",
       "      <td>8.776794</td>\n",
       "      <td>21.411765</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>150</td>\n",
       "      <td>Challenges and Opportunities of Big Data in He...</td>\n",
       "      <td>big data|to begin explain big data important l...</td>\n",
       "      <td>30</td>\n",
       "      <td>36</td>\n",
       "      <td>-0.090909</td>\n",
       "      <td>0.138655</td>\n",
       "      <td>39.666667</td>\n",
       "      <td>0.378151</td>\n",
       "      <td>16.017927</td>\n",
       "      <td>39.666667</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>111 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     URL_ID                                              Title  \\\n",
       "0        37       AI in healthcare to Improve Patient Outcomes   \n",
       "1        38   What if the Creation is Taking Over the Creator?   \n",
       "2        39  What Jobs Will Robots Take From Humans in The ...   \n",
       "3        40  Will Machine Replace The Human in the Future o...   \n",
       "4        41                Will AI Replace Us or Work With Us?   \n",
       "..      ...                                                ...   \n",
       "106     146                            Blockchain for Payments   \n",
       "107     147                            The future of Investing   \n",
       "108     148                   Big Data Analytics in Healthcare   \n",
       "109     149      Business Analytics In The Healthcare Industry   \n",
       "110     150  Challenges and Opportunities of Big Data in He...   \n",
       "\n",
       "                                                  Text  positive_score  \\\n",
       "0    introduction|if kills people decades highly in...              58   \n",
       "1    human minds fascination carrying potential tin...              55   \n",
       "2    introduction|ai rapidly evolving employment se...              64   \n",
       "3    give rise smarterthanhuman intelligence form a...              59   \n",
       "4    machine intelligence invention humanity make|n...              54   \n",
       "..                                                 ...             ...   \n",
       "106  reconciling financial realities mba education ...              20   \n",
       "107  investment|an investment resource thing procur...              33   \n",
       "108  quality affordable healthcare vision governmen...              26   \n",
       "109  analytics statistical scientific process disco...              35   \n",
       "110  big data|to begin explain big data important l...              30   \n",
       "\n",
       "     negative_score  polarity_score  subjectivity_score  Avg Sentence Length  \\\n",
       "0                30        0.318182            0.095032            28.060606   \n",
       "1                35        0.222222            0.165746            36.200000   \n",
       "2                34        0.306122            0.122653            28.535714   \n",
       "3                21        0.475000            0.132890            17.705882   \n",
       "4                24        0.384615            0.105978            19.368421   \n",
       "..              ...             ...                 ...                  ...   \n",
       "106              25       -0.111111            0.110024            22.722222   \n",
       "107              10        0.534884            0.063988            19.764706   \n",
       "108              41       -0.223881            0.120939            25.181818   \n",
       "109               4        0.794872            0.107143            21.411765   \n",
       "110              36       -0.090909            0.138655            39.666667   \n",
       "\n",
       "     Percentage of Complex words  Fog Index  Avg Words Per Sentence  \\\n",
       "0                       0.451404  11.404804               28.060606   \n",
       "1                       0.395948  14.638379               36.200000   \n",
       "2                       0.468085  11.601520               28.535714   \n",
       "3                       0.377076   7.233184               17.705882   \n",
       "4                       0.421196   7.915847               19.368421   \n",
       "..                           ...        ...                     ...   \n",
       "106                     0.408313   9.252214               22.722222   \n",
       "107                     0.403274   8.067192               19.764706   \n",
       "108                     0.393502  10.230128               25.181818   \n",
       "109                     0.530220   8.776794               21.411765   \n",
       "110                     0.378151  16.017927               39.666667   \n",
       "\n",
       "     Complex word count  \n",
       "0                   418  \n",
       "1                   215  \n",
       "2                   374  \n",
       "3                   227  \n",
       "4                   310  \n",
       "..                  ...  \n",
       "106                 167  \n",
       "107                 271  \n",
       "108                 218  \n",
       "109                 193  \n",
       "110                 180  \n",
       "\n",
       "[111 rows x 12 columns]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b7a41e",
   "metadata": {},
   "source": [
    "### Word Count & Syllable Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "0f4944e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_count(text):\n",
    "    words = word_tokenize(text)\n",
    "    return len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "d303ce17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Word Count'] = df['Text'].apply(word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "e79aa15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_syllables_per_word(text):\n",
    "    words = word_tokenize(text)\n",
    "    syllables_per_word = [count_syllables(word) for word in words]\n",
    "    return syllables_per_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "200a98fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Syllables per Word'] = df['Text'].apply(count_syllables_per_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "450aafad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Text</th>\n",
       "      <th>positive_score</th>\n",
       "      <th>negative_score</th>\n",
       "      <th>polarity_score</th>\n",
       "      <th>subjectivity_score</th>\n",
       "      <th>Avg Sentence Length</th>\n",
       "      <th>Percentage of Complex words</th>\n",
       "      <th>Fog Index</th>\n",
       "      <th>Avg Words Per Sentence</th>\n",
       "      <th>Complex word count</th>\n",
       "      <th>Word Count</th>\n",
       "      <th>Syllables per Word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>AI in healthcare to Improve Patient Outcomes</td>\n",
       "      <td>introduction|if kills people decades highly in...</td>\n",
       "      <td>58</td>\n",
       "      <td>30</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.095032</td>\n",
       "      <td>28.060606</td>\n",
       "      <td>0.451404</td>\n",
       "      <td>11.404804</td>\n",
       "      <td>28.060606</td>\n",
       "      <td>418</td>\n",
       "      <td>926</td>\n",
       "      <td>[5, 1, 1, 3, 1, 3, 2, 1, 3, 3, 2, 2, 3, 1, 3, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>What if the Creation is Taking Over the Creator?</td>\n",
       "      <td>human minds fascination carrying potential tin...</td>\n",
       "      <td>55</td>\n",
       "      <td>35</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.165746</td>\n",
       "      <td>36.200000</td>\n",
       "      <td>0.395948</td>\n",
       "      <td>14.638379</td>\n",
       "      <td>36.200000</td>\n",
       "      <td>215</td>\n",
       "      <td>543</td>\n",
       "      <td>[2, 1, 4, 2, 3, 3, 2, 1, 1, 4, 2, 2, 2, 2, 4, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>What Jobs Will Robots Take From Humans in The ...</td>\n",
       "      <td>introduction|ai rapidly evolving employment se...</td>\n",
       "      <td>64</td>\n",
       "      <td>34</td>\n",
       "      <td>0.306122</td>\n",
       "      <td>0.122653</td>\n",
       "      <td>28.535714</td>\n",
       "      <td>0.468085</td>\n",
       "      <td>11.601520</td>\n",
       "      <td>28.535714</td>\n",
       "      <td>374</td>\n",
       "      <td>799</td>\n",
       "      <td>[5, 2, 3, 3, 2, 2, 3, 3, 2, 2, 4, 4, 3, 3, 4, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>Will Machine Replace The Human in the Future o...</td>\n",
       "      <td>give rise smarterthanhuman intelligence form a...</td>\n",
       "      <td>59</td>\n",
       "      <td>21</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.132890</td>\n",
       "      <td>17.705882</td>\n",
       "      <td>0.377076</td>\n",
       "      <td>7.233184</td>\n",
       "      <td>17.705882</td>\n",
       "      <td>227</td>\n",
       "      <td>602</td>\n",
       "      <td>[1, 1, 5, 4, 1, 4, 4, 4, 4, 6, 2, 4, 4, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>Will AI Replace Us or Work With Us?</td>\n",
       "      <td>machine intelligence invention humanity make|n...</td>\n",
       "      <td>54</td>\n",
       "      <td>24</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.105978</td>\n",
       "      <td>19.368421</td>\n",
       "      <td>0.421196</td>\n",
       "      <td>7.915847</td>\n",
       "      <td>19.368421</td>\n",
       "      <td>310</td>\n",
       "      <td>736</td>\n",
       "      <td>[2, 4, 3, 3, 3, 3, 1, 1, 4, 4, 3, 2, 1, 2, 2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>146</td>\n",
       "      <td>Blockchain for Payments</td>\n",
       "      <td>reconciling financial realities mba education ...</td>\n",
       "      <td>20</td>\n",
       "      <td>25</td>\n",
       "      <td>-0.111111</td>\n",
       "      <td>0.110024</td>\n",
       "      <td>22.722222</td>\n",
       "      <td>0.408313</td>\n",
       "      <td>9.252214</td>\n",
       "      <td>22.722222</td>\n",
       "      <td>167</td>\n",
       "      <td>409</td>\n",
       "      <td>[4, 3, 3, 1, 4, 1, 3, 1, 4, 1, 3, 1, 2, 2, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>147</td>\n",
       "      <td>The future of Investing</td>\n",
       "      <td>investment|an investment resource thing procur...</td>\n",
       "      <td>33</td>\n",
       "      <td>10</td>\n",
       "      <td>0.534884</td>\n",
       "      <td>0.063988</td>\n",
       "      <td>19.764706</td>\n",
       "      <td>0.403274</td>\n",
       "      <td>8.067192</td>\n",
       "      <td>19.764706</td>\n",
       "      <td>271</td>\n",
       "      <td>672</td>\n",
       "      <td>[4, 3, 2, 1, 3, 3, 3, 1, 4, 5, 3, 1, 2, 3, 3, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>148</td>\n",
       "      <td>Big Data Analytics in Healthcare</td>\n",
       "      <td>quality affordable healthcare vision governmen...</td>\n",
       "      <td>26</td>\n",
       "      <td>41</td>\n",
       "      <td>-0.223881</td>\n",
       "      <td>0.120939</td>\n",
       "      <td>25.181818</td>\n",
       "      <td>0.393502</td>\n",
       "      <td>10.230128</td>\n",
       "      <td>25.181818</td>\n",
       "      <td>218</td>\n",
       "      <td>554</td>\n",
       "      <td>[2, 3, 2, 2, 3, 1, 1, 3, 2, 1, 3, 4, 4, 2, 4, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>149</td>\n",
       "      <td>Business Analytics In The Healthcare Industry</td>\n",
       "      <td>analytics statistical scientific process disco...</td>\n",
       "      <td>35</td>\n",
       "      <td>4</td>\n",
       "      <td>0.794872</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>21.411765</td>\n",
       "      <td>0.530220</td>\n",
       "      <td>8.776794</td>\n",
       "      <td>21.411765</td>\n",
       "      <td>193</td>\n",
       "      <td>364</td>\n",
       "      <td>[3, 4, 3, 2, 4, 3, 3, 2, 1, 2, 3, 3, 2, 1, 4, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>150</td>\n",
       "      <td>Challenges and Opportunities of Big Data in He...</td>\n",
       "      <td>big data|to begin explain big data important l...</td>\n",
       "      <td>30</td>\n",
       "      <td>36</td>\n",
       "      <td>-0.090909</td>\n",
       "      <td>0.138655</td>\n",
       "      <td>39.666667</td>\n",
       "      <td>0.378151</td>\n",
       "      <td>16.017927</td>\n",
       "      <td>39.666667</td>\n",
       "      <td>180</td>\n",
       "      <td>476</td>\n",
       "      <td>[1, 3, 2, 2, 1, 2, 3, 2, 1, 2, 1, 2, 1, 1, 2, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>111 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     URL_ID                                              Title  \\\n",
       "0        37       AI in healthcare to Improve Patient Outcomes   \n",
       "1        38   What if the Creation is Taking Over the Creator?   \n",
       "2        39  What Jobs Will Robots Take From Humans in The ...   \n",
       "3        40  Will Machine Replace The Human in the Future o...   \n",
       "4        41                Will AI Replace Us or Work With Us?   \n",
       "..      ...                                                ...   \n",
       "106     146                            Blockchain for Payments   \n",
       "107     147                            The future of Investing   \n",
       "108     148                   Big Data Analytics in Healthcare   \n",
       "109     149      Business Analytics In The Healthcare Industry   \n",
       "110     150  Challenges and Opportunities of Big Data in He...   \n",
       "\n",
       "                                                  Text  positive_score  \\\n",
       "0    introduction|if kills people decades highly in...              58   \n",
       "1    human minds fascination carrying potential tin...              55   \n",
       "2    introduction|ai rapidly evolving employment se...              64   \n",
       "3    give rise smarterthanhuman intelligence form a...              59   \n",
       "4    machine intelligence invention humanity make|n...              54   \n",
       "..                                                 ...             ...   \n",
       "106  reconciling financial realities mba education ...              20   \n",
       "107  investment|an investment resource thing procur...              33   \n",
       "108  quality affordable healthcare vision governmen...              26   \n",
       "109  analytics statistical scientific process disco...              35   \n",
       "110  big data|to begin explain big data important l...              30   \n",
       "\n",
       "     negative_score  polarity_score  subjectivity_score  Avg Sentence Length  \\\n",
       "0                30        0.318182            0.095032            28.060606   \n",
       "1                35        0.222222            0.165746            36.200000   \n",
       "2                34        0.306122            0.122653            28.535714   \n",
       "3                21        0.475000            0.132890            17.705882   \n",
       "4                24        0.384615            0.105978            19.368421   \n",
       "..              ...             ...                 ...                  ...   \n",
       "106              25       -0.111111            0.110024            22.722222   \n",
       "107              10        0.534884            0.063988            19.764706   \n",
       "108              41       -0.223881            0.120939            25.181818   \n",
       "109               4        0.794872            0.107143            21.411765   \n",
       "110              36       -0.090909            0.138655            39.666667   \n",
       "\n",
       "     Percentage of Complex words  Fog Index  Avg Words Per Sentence  \\\n",
       "0                       0.451404  11.404804               28.060606   \n",
       "1                       0.395948  14.638379               36.200000   \n",
       "2                       0.468085  11.601520               28.535714   \n",
       "3                       0.377076   7.233184               17.705882   \n",
       "4                       0.421196   7.915847               19.368421   \n",
       "..                           ...        ...                     ...   \n",
       "106                     0.408313   9.252214               22.722222   \n",
       "107                     0.403274   8.067192               19.764706   \n",
       "108                     0.393502  10.230128               25.181818   \n",
       "109                     0.530220   8.776794               21.411765   \n",
       "110                     0.378151  16.017927               39.666667   \n",
       "\n",
       "     Complex word count  Word Count  \\\n",
       "0                   418         926   \n",
       "1                   215         543   \n",
       "2                   374         799   \n",
       "3                   227         602   \n",
       "4                   310         736   \n",
       "..                  ...         ...   \n",
       "106                 167         409   \n",
       "107                 271         672   \n",
       "108                 218         554   \n",
       "109                 193         364   \n",
       "110                 180         476   \n",
       "\n",
       "                                    Syllables per Word  \n",
       "0    [5, 1, 1, 3, 1, 3, 2, 1, 3, 3, 2, 2, 3, 1, 3, ...  \n",
       "1    [2, 1, 4, 2, 3, 3, 2, 1, 1, 4, 2, 2, 2, 2, 4, ...  \n",
       "2    [5, 2, 3, 3, 2, 2, 3, 3, 2, 2, 4, 4, 3, 3, 4, ...  \n",
       "3    [1, 1, 5, 4, 1, 4, 4, 4, 4, 6, 2, 4, 4, 1, 1, ...  \n",
       "4    [2, 4, 3, 3, 3, 3, 1, 1, 4, 4, 3, 2, 1, 2, 2, ...  \n",
       "..                                                 ...  \n",
       "106  [4, 3, 3, 1, 4, 1, 3, 1, 4, 1, 3, 1, 2, 2, 1, ...  \n",
       "107  [4, 3, 2, 1, 3, 3, 3, 1, 4, 5, 3, 1, 2, 3, 3, ...  \n",
       "108  [2, 3, 2, 2, 3, 1, 1, 3, 2, 1, 3, 4, 4, 2, 4, ...  \n",
       "109  [3, 4, 3, 2, 4, 3, 3, 2, 1, 2, 3, 3, 2, 1, 4, ...  \n",
       "110  [1, 3, 2, 2, 1, 2, 3, 2, 1, 2, 1, 2, 1, 1, 2, ...  \n",
       "\n",
       "[111 rows x 14 columns]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fee35bb",
   "metadata": {},
   "source": [
    "### Personal Pronouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "7c0dfe79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_personal_pronouns(text):\n",
    "    # Define the regular expression pattern to match personal pronouns\n",
    "    pattern = re.compile(r\"\\b(I|we|my|ours|us)\\b\", re.IGNORECASE)\n",
    "    \n",
    "    # Use re.findall to search for all occurrences of the pattern in the text\n",
    "    matches = re.findall(pattern, text)\n",
    "    \n",
    "    # Return the count of personal pronouns\n",
    "    return len(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "7430fb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Personal Pronouns\"] = df[\"Text\"].apply(count_personal_pronouns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a28aed1",
   "metadata": {},
   "source": [
    "### Average Word Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "4ed41190",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_word_length(text):\n",
    "    words = text.split()\n",
    "    return sum(len(word) for word in words) / len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "0cd26b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Average Word Length\"] = df[\"Text\"].apply(avg_word_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "c8cb0174",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Text</th>\n",
       "      <th>positive_score</th>\n",
       "      <th>negative_score</th>\n",
       "      <th>polarity_score</th>\n",
       "      <th>subjectivity_score</th>\n",
       "      <th>Avg Sentence Length</th>\n",
       "      <th>Percentage of Complex words</th>\n",
       "      <th>Fog Index</th>\n",
       "      <th>Avg Words Per Sentence</th>\n",
       "      <th>Complex word count</th>\n",
       "      <th>Word Count</th>\n",
       "      <th>Syllables per Word</th>\n",
       "      <th>Personal Pronouns</th>\n",
       "      <th>Average Word Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>AI in healthcare to Improve Patient Outcomes</td>\n",
       "      <td>introduction|if kills people decades highly in...</td>\n",
       "      <td>58</td>\n",
       "      <td>30</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.095032</td>\n",
       "      <td>28.060606</td>\n",
       "      <td>0.451404</td>\n",
       "      <td>11.404804</td>\n",
       "      <td>28.060606</td>\n",
       "      <td>418</td>\n",
       "      <td>926</td>\n",
       "      <td>[5, 1, 1, 3, 1, 3, 2, 1, 3, 3, 2, 2, 3, 1, 3, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>7.989201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>What if the Creation is Taking Over the Creator?</td>\n",
       "      <td>human minds fascination carrying potential tin...</td>\n",
       "      <td>55</td>\n",
       "      <td>35</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.165746</td>\n",
       "      <td>36.200000</td>\n",
       "      <td>0.395948</td>\n",
       "      <td>14.638379</td>\n",
       "      <td>36.200000</td>\n",
       "      <td>215</td>\n",
       "      <td>543</td>\n",
       "      <td>[2, 1, 4, 2, 3, 3, 2, 1, 1, 4, 2, 2, 2, 2, 4, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>7.364641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>What Jobs Will Robots Take From Humans in The ...</td>\n",
       "      <td>introduction|ai rapidly evolving employment se...</td>\n",
       "      <td>64</td>\n",
       "      <td>34</td>\n",
       "      <td>0.306122</td>\n",
       "      <td>0.122653</td>\n",
       "      <td>28.535714</td>\n",
       "      <td>0.468085</td>\n",
       "      <td>11.601520</td>\n",
       "      <td>28.535714</td>\n",
       "      <td>374</td>\n",
       "      <td>799</td>\n",
       "      <td>[5, 2, 3, 3, 2, 2, 3, 3, 2, 2, 4, 4, 3, 3, 4, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>7.968711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>Will Machine Replace The Human in the Future o...</td>\n",
       "      <td>give rise smarterthanhuman intelligence form a...</td>\n",
       "      <td>59</td>\n",
       "      <td>21</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.132890</td>\n",
       "      <td>17.705882</td>\n",
       "      <td>0.377076</td>\n",
       "      <td>7.233184</td>\n",
       "      <td>17.705882</td>\n",
       "      <td>227</td>\n",
       "      <td>602</td>\n",
       "      <td>[1, 1, 5, 4, 1, 4, 4, 4, 4, 6, 2, 4, 4, 1, 1, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>7.528239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>Will AI Replace Us or Work With Us?</td>\n",
       "      <td>machine intelligence invention humanity make|n...</td>\n",
       "      <td>54</td>\n",
       "      <td>24</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.105978</td>\n",
       "      <td>19.368421</td>\n",
       "      <td>0.421196</td>\n",
       "      <td>7.915847</td>\n",
       "      <td>19.368421</td>\n",
       "      <td>310</td>\n",
       "      <td>736</td>\n",
       "      <td>[2, 4, 3, 3, 3, 3, 1, 1, 4, 4, 3, 2, 1, 2, 2, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>7.701087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>146</td>\n",
       "      <td>Blockchain for Payments</td>\n",
       "      <td>reconciling financial realities mba education ...</td>\n",
       "      <td>20</td>\n",
       "      <td>25</td>\n",
       "      <td>-0.111111</td>\n",
       "      <td>0.110024</td>\n",
       "      <td>22.722222</td>\n",
       "      <td>0.408313</td>\n",
       "      <td>9.252214</td>\n",
       "      <td>22.722222</td>\n",
       "      <td>167</td>\n",
       "      <td>409</td>\n",
       "      <td>[4, 3, 3, 1, 4, 1, 3, 1, 4, 1, 3, 1, 2, 2, 1, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>8.002445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>147</td>\n",
       "      <td>The future of Investing</td>\n",
       "      <td>investment|an investment resource thing procur...</td>\n",
       "      <td>33</td>\n",
       "      <td>10</td>\n",
       "      <td>0.534884</td>\n",
       "      <td>0.063988</td>\n",
       "      <td>19.764706</td>\n",
       "      <td>0.403274</td>\n",
       "      <td>8.067192</td>\n",
       "      <td>19.764706</td>\n",
       "      <td>271</td>\n",
       "      <td>672</td>\n",
       "      <td>[4, 3, 2, 1, 3, 3, 3, 1, 4, 5, 3, 1, 2, 3, 3, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>7.552083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>148</td>\n",
       "      <td>Big Data Analytics in Healthcare</td>\n",
       "      <td>quality affordable healthcare vision governmen...</td>\n",
       "      <td>26</td>\n",
       "      <td>41</td>\n",
       "      <td>-0.223881</td>\n",
       "      <td>0.120939</td>\n",
       "      <td>25.181818</td>\n",
       "      <td>0.393502</td>\n",
       "      <td>10.230128</td>\n",
       "      <td>25.181818</td>\n",
       "      <td>218</td>\n",
       "      <td>554</td>\n",
       "      <td>[2, 3, 2, 2, 3, 1, 1, 3, 2, 1, 3, 4, 4, 2, 4, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>7.373646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>149</td>\n",
       "      <td>Business Analytics In The Healthcare Industry</td>\n",
       "      <td>analytics statistical scientific process disco...</td>\n",
       "      <td>35</td>\n",
       "      <td>4</td>\n",
       "      <td>0.794872</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>21.411765</td>\n",
       "      <td>0.530220</td>\n",
       "      <td>8.776794</td>\n",
       "      <td>21.411765</td>\n",
       "      <td>193</td>\n",
       "      <td>364</td>\n",
       "      <td>[3, 4, 3, 2, 4, 3, 3, 2, 1, 2, 3, 3, 2, 1, 4, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>8.343407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>150</td>\n",
       "      <td>Challenges and Opportunities of Big Data in He...</td>\n",
       "      <td>big data|to begin explain big data important l...</td>\n",
       "      <td>30</td>\n",
       "      <td>36</td>\n",
       "      <td>-0.090909</td>\n",
       "      <td>0.138655</td>\n",
       "      <td>39.666667</td>\n",
       "      <td>0.378151</td>\n",
       "      <td>16.017927</td>\n",
       "      <td>39.666667</td>\n",
       "      <td>180</td>\n",
       "      <td>476</td>\n",
       "      <td>[1, 3, 2, 2, 1, 2, 3, 2, 1, 2, 1, 2, 1, 1, 2, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>7.365546</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>111 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     URL_ID                                              Title  \\\n",
       "0        37       AI in healthcare to Improve Patient Outcomes   \n",
       "1        38   What if the Creation is Taking Over the Creator?   \n",
       "2        39  What Jobs Will Robots Take From Humans in The ...   \n",
       "3        40  Will Machine Replace The Human in the Future o...   \n",
       "4        41                Will AI Replace Us or Work With Us?   \n",
       "..      ...                                                ...   \n",
       "106     146                            Blockchain for Payments   \n",
       "107     147                            The future of Investing   \n",
       "108     148                   Big Data Analytics in Healthcare   \n",
       "109     149      Business Analytics In The Healthcare Industry   \n",
       "110     150  Challenges and Opportunities of Big Data in He...   \n",
       "\n",
       "                                                  Text  positive_score  \\\n",
       "0    introduction|if kills people decades highly in...              58   \n",
       "1    human minds fascination carrying potential tin...              55   \n",
       "2    introduction|ai rapidly evolving employment se...              64   \n",
       "3    give rise smarterthanhuman intelligence form a...              59   \n",
       "4    machine intelligence invention humanity make|n...              54   \n",
       "..                                                 ...             ...   \n",
       "106  reconciling financial realities mba education ...              20   \n",
       "107  investment|an investment resource thing procur...              33   \n",
       "108  quality affordable healthcare vision governmen...              26   \n",
       "109  analytics statistical scientific process disco...              35   \n",
       "110  big data|to begin explain big data important l...              30   \n",
       "\n",
       "     negative_score  polarity_score  subjectivity_score  Avg Sentence Length  \\\n",
       "0                30        0.318182            0.095032            28.060606   \n",
       "1                35        0.222222            0.165746            36.200000   \n",
       "2                34        0.306122            0.122653            28.535714   \n",
       "3                21        0.475000            0.132890            17.705882   \n",
       "4                24        0.384615            0.105978            19.368421   \n",
       "..              ...             ...                 ...                  ...   \n",
       "106              25       -0.111111            0.110024            22.722222   \n",
       "107              10        0.534884            0.063988            19.764706   \n",
       "108              41       -0.223881            0.120939            25.181818   \n",
       "109               4        0.794872            0.107143            21.411765   \n",
       "110              36       -0.090909            0.138655            39.666667   \n",
       "\n",
       "     Percentage of Complex words  Fog Index  Avg Words Per Sentence  \\\n",
       "0                       0.451404  11.404804               28.060606   \n",
       "1                       0.395948  14.638379               36.200000   \n",
       "2                       0.468085  11.601520               28.535714   \n",
       "3                       0.377076   7.233184               17.705882   \n",
       "4                       0.421196   7.915847               19.368421   \n",
       "..                           ...        ...                     ...   \n",
       "106                     0.408313   9.252214               22.722222   \n",
       "107                     0.403274   8.067192               19.764706   \n",
       "108                     0.393502  10.230128               25.181818   \n",
       "109                     0.530220   8.776794               21.411765   \n",
       "110                     0.378151  16.017927               39.666667   \n",
       "\n",
       "     Complex word count  Word Count  \\\n",
       "0                   418         926   \n",
       "1                   215         543   \n",
       "2                   374         799   \n",
       "3                   227         602   \n",
       "4                   310         736   \n",
       "..                  ...         ...   \n",
       "106                 167         409   \n",
       "107                 271         672   \n",
       "108                 218         554   \n",
       "109                 193         364   \n",
       "110                 180         476   \n",
       "\n",
       "                                    Syllables per Word  Personal Pronouns  \\\n",
       "0    [5, 1, 1, 3, 1, 3, 2, 1, 3, 3, 2, 2, 3, 1, 3, ...                  0   \n",
       "1    [2, 1, 4, 2, 3, 3, 2, 1, 1, 4, 2, 2, 2, 2, 4, ...                  0   \n",
       "2    [5, 2, 3, 3, 2, 2, 3, 3, 2, 2, 4, 4, 3, 3, 4, ...                  0   \n",
       "3    [1, 1, 5, 4, 1, 4, 4, 4, 4, 6, 2, 4, 4, 1, 1, ...                  0   \n",
       "4    [2, 4, 3, 3, 3, 3, 1, 1, 4, 4, 3, 2, 1, 2, 2, ...                  1   \n",
       "..                                                 ...                ...   \n",
       "106  [4, 3, 3, 1, 4, 1, 3, 1, 4, 1, 3, 1, 2, 2, 1, ...                  0   \n",
       "107  [4, 3, 2, 1, 3, 3, 3, 1, 4, 5, 3, 1, 2, 3, 3, ...                  0   \n",
       "108  [2, 3, 2, 2, 3, 1, 1, 3, 2, 1, 3, 4, 4, 2, 4, ...                  0   \n",
       "109  [3, 4, 3, 2, 4, 3, 3, 2, 1, 2, 3, 3, 2, 1, 4, ...                  0   \n",
       "110  [1, 3, 2, 2, 1, 2, 3, 2, 1, 2, 1, 2, 1, 1, 2, ...                  0   \n",
       "\n",
       "     Average Word Length  \n",
       "0               7.989201  \n",
       "1               7.364641  \n",
       "2               7.968711  \n",
       "3               7.528239  \n",
       "4               7.701087  \n",
       "..                   ...  \n",
       "106             8.002445  \n",
       "107             7.552083  \n",
       "108             7.373646  \n",
       "109             8.343407  \n",
       "110             7.365546  \n",
       "\n",
       "[111 rows x 16 columns]"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "837f6589",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_input_data = input_data[~input_data[\"URL_ID\"].isin([44, 57, 144])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "e3f45cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.insert(2, \"URL\", filtered_input_data[\"URL\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "ec6d5656",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>Title</th>\n",
       "      <th>URL</th>\n",
       "      <th>Text</th>\n",
       "      <th>positive_score</th>\n",
       "      <th>negative_score</th>\n",
       "      <th>polarity_score</th>\n",
       "      <th>subjectivity_score</th>\n",
       "      <th>Avg Sentence Length</th>\n",
       "      <th>Percentage of Complex words</th>\n",
       "      <th>Fog Index</th>\n",
       "      <th>Avg Words Per Sentence</th>\n",
       "      <th>Complex word count</th>\n",
       "      <th>Word Count</th>\n",
       "      <th>Syllables per Word</th>\n",
       "      <th>Personal Pronouns</th>\n",
       "      <th>Average Word Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>AI in healthcare to Improve Patient Outcomes</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-in-healthc...</td>\n",
       "      <td>introduction|if kills people decades highly in...</td>\n",
       "      <td>58</td>\n",
       "      <td>30</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.095032</td>\n",
       "      <td>28.060606</td>\n",
       "      <td>0.451404</td>\n",
       "      <td>11.404804</td>\n",
       "      <td>28.060606</td>\n",
       "      <td>418</td>\n",
       "      <td>926</td>\n",
       "      <td>[5, 1, 1, 3, 1, 3, 2, 1, 3, 3, 2, 2, 3, 1, 3, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>7.989201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>What if the Creation is Taking Over the Creator?</td>\n",
       "      <td>https://insights.blackcoffer.com/what-if-the-c...</td>\n",
       "      <td>human minds fascination carrying potential tin...</td>\n",
       "      <td>55</td>\n",
       "      <td>35</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.165746</td>\n",
       "      <td>36.200000</td>\n",
       "      <td>0.395948</td>\n",
       "      <td>14.638379</td>\n",
       "      <td>36.200000</td>\n",
       "      <td>215</td>\n",
       "      <td>543</td>\n",
       "      <td>[2, 1, 4, 2, 3, 3, 2, 1, 1, 4, 2, 2, 2, 2, 4, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>7.364641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>What Jobs Will Robots Take From Humans in The ...</td>\n",
       "      <td>https://insights.blackcoffer.com/what-jobs-wil...</td>\n",
       "      <td>introduction|ai rapidly evolving employment se...</td>\n",
       "      <td>64</td>\n",
       "      <td>34</td>\n",
       "      <td>0.306122</td>\n",
       "      <td>0.122653</td>\n",
       "      <td>28.535714</td>\n",
       "      <td>0.468085</td>\n",
       "      <td>11.601520</td>\n",
       "      <td>28.535714</td>\n",
       "      <td>374</td>\n",
       "      <td>799</td>\n",
       "      <td>[5, 2, 3, 3, 2, 2, 3, 3, 2, 2, 4, 4, 3, 3, 4, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>7.968711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>Will Machine Replace The Human in the Future o...</td>\n",
       "      <td>https://insights.blackcoffer.com/will-machine-...</td>\n",
       "      <td>give rise smarterthanhuman intelligence form a...</td>\n",
       "      <td>59</td>\n",
       "      <td>21</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.132890</td>\n",
       "      <td>17.705882</td>\n",
       "      <td>0.377076</td>\n",
       "      <td>7.233184</td>\n",
       "      <td>17.705882</td>\n",
       "      <td>227</td>\n",
       "      <td>602</td>\n",
       "      <td>[1, 1, 5, 4, 1, 4, 4, 4, 4, 6, 2, 4, 4, 1, 1, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>7.528239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>Will AI Replace Us or Work With Us?</td>\n",
       "      <td>https://insights.blackcoffer.com/will-ai-repla...</td>\n",
       "      <td>machine intelligence invention humanity make|n...</td>\n",
       "      <td>54</td>\n",
       "      <td>24</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.105978</td>\n",
       "      <td>19.368421</td>\n",
       "      <td>0.421196</td>\n",
       "      <td>7.915847</td>\n",
       "      <td>19.368421</td>\n",
       "      <td>310</td>\n",
       "      <td>736</td>\n",
       "      <td>[2, 4, 3, 3, 3, 3, 1, 1, 4, 4, 3, 2, 1, 2, 2, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>7.701087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>146</td>\n",
       "      <td>Blockchain for Payments</td>\n",
       "      <td>https://insights.blackcoffer.com/impact-of-cov...</td>\n",
       "      <td>reconciling financial realities mba education ...</td>\n",
       "      <td>20</td>\n",
       "      <td>25</td>\n",
       "      <td>-0.111111</td>\n",
       "      <td>0.110024</td>\n",
       "      <td>22.722222</td>\n",
       "      <td>0.408313</td>\n",
       "      <td>9.252214</td>\n",
       "      <td>22.722222</td>\n",
       "      <td>167</td>\n",
       "      <td>409</td>\n",
       "      <td>[4, 3, 3, 1, 4, 1, 3, 1, 4, 1, 3, 1, 2, 2, 1, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>8.002445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>147</td>\n",
       "      <td>The future of Investing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>investment|an investment resource thing procur...</td>\n",
       "      <td>33</td>\n",
       "      <td>10</td>\n",
       "      <td>0.534884</td>\n",
       "      <td>0.063988</td>\n",
       "      <td>19.764706</td>\n",
       "      <td>0.403274</td>\n",
       "      <td>8.067192</td>\n",
       "      <td>19.764706</td>\n",
       "      <td>271</td>\n",
       "      <td>672</td>\n",
       "      <td>[4, 3, 2, 1, 3, 3, 3, 1, 4, 5, 3, 1, 2, 3, 3, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>7.552083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>148</td>\n",
       "      <td>Big Data Analytics in Healthcare</td>\n",
       "      <td>https://insights.blackcoffer.com/blockchain-in...</td>\n",
       "      <td>quality affordable healthcare vision governmen...</td>\n",
       "      <td>26</td>\n",
       "      <td>41</td>\n",
       "      <td>-0.223881</td>\n",
       "      <td>0.120939</td>\n",
       "      <td>25.181818</td>\n",
       "      <td>0.393502</td>\n",
       "      <td>10.230128</td>\n",
       "      <td>25.181818</td>\n",
       "      <td>218</td>\n",
       "      <td>554</td>\n",
       "      <td>[2, 3, 2, 2, 3, 1, 1, 3, 2, 1, 3, 4, 4, 2, 4, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>7.373646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>149</td>\n",
       "      <td>Business Analytics In The Healthcare Industry</td>\n",
       "      <td>https://insights.blackcoffer.com/blockchain-fo...</td>\n",
       "      <td>analytics statistical scientific process disco...</td>\n",
       "      <td>35</td>\n",
       "      <td>4</td>\n",
       "      <td>0.794872</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>21.411765</td>\n",
       "      <td>0.530220</td>\n",
       "      <td>8.776794</td>\n",
       "      <td>21.411765</td>\n",
       "      <td>193</td>\n",
       "      <td>364</td>\n",
       "      <td>[3, 4, 3, 2, 4, 3, 3, 2, 1, 2, 3, 3, 2, 1, 4, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>8.343407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>150</td>\n",
       "      <td>Challenges and Opportunities of Big Data in He...</td>\n",
       "      <td>https://insights.blackcoffer.com/the-future-of...</td>\n",
       "      <td>big data|to begin explain big data important l...</td>\n",
       "      <td>30</td>\n",
       "      <td>36</td>\n",
       "      <td>-0.090909</td>\n",
       "      <td>0.138655</td>\n",
       "      <td>39.666667</td>\n",
       "      <td>0.378151</td>\n",
       "      <td>16.017927</td>\n",
       "      <td>39.666667</td>\n",
       "      <td>180</td>\n",
       "      <td>476</td>\n",
       "      <td>[1, 3, 2, 2, 1, 2, 3, 2, 1, 2, 1, 2, 1, 1, 2, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>7.365546</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>111 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     URL_ID                                              Title  \\\n",
       "0        37       AI in healthcare to Improve Patient Outcomes   \n",
       "1        38   What if the Creation is Taking Over the Creator?   \n",
       "2        39  What Jobs Will Robots Take From Humans in The ...   \n",
       "3        40  Will Machine Replace The Human in the Future o...   \n",
       "4        41                Will AI Replace Us or Work With Us?   \n",
       "..      ...                                                ...   \n",
       "106     146                            Blockchain for Payments   \n",
       "107     147                            The future of Investing   \n",
       "108     148                   Big Data Analytics in Healthcare   \n",
       "109     149      Business Analytics In The Healthcare Industry   \n",
       "110     150  Challenges and Opportunities of Big Data in He...   \n",
       "\n",
       "                                                   URL  \\\n",
       "0    https://insights.blackcoffer.com/ai-in-healthc...   \n",
       "1    https://insights.blackcoffer.com/what-if-the-c...   \n",
       "2    https://insights.blackcoffer.com/what-jobs-wil...   \n",
       "3    https://insights.blackcoffer.com/will-machine-...   \n",
       "4    https://insights.blackcoffer.com/will-ai-repla...   \n",
       "..                                                 ...   \n",
       "106  https://insights.blackcoffer.com/impact-of-cov...   \n",
       "107                                                NaN   \n",
       "108  https://insights.blackcoffer.com/blockchain-in...   \n",
       "109  https://insights.blackcoffer.com/blockchain-fo...   \n",
       "110  https://insights.blackcoffer.com/the-future-of...   \n",
       "\n",
       "                                                  Text  positive_score  \\\n",
       "0    introduction|if kills people decades highly in...              58   \n",
       "1    human minds fascination carrying potential tin...              55   \n",
       "2    introduction|ai rapidly evolving employment se...              64   \n",
       "3    give rise smarterthanhuman intelligence form a...              59   \n",
       "4    machine intelligence invention humanity make|n...              54   \n",
       "..                                                 ...             ...   \n",
       "106  reconciling financial realities mba education ...              20   \n",
       "107  investment|an investment resource thing procur...              33   \n",
       "108  quality affordable healthcare vision governmen...              26   \n",
       "109  analytics statistical scientific process disco...              35   \n",
       "110  big data|to begin explain big data important l...              30   \n",
       "\n",
       "     negative_score  polarity_score  subjectivity_score  Avg Sentence Length  \\\n",
       "0                30        0.318182            0.095032            28.060606   \n",
       "1                35        0.222222            0.165746            36.200000   \n",
       "2                34        0.306122            0.122653            28.535714   \n",
       "3                21        0.475000            0.132890            17.705882   \n",
       "4                24        0.384615            0.105978            19.368421   \n",
       "..              ...             ...                 ...                  ...   \n",
       "106              25       -0.111111            0.110024            22.722222   \n",
       "107              10        0.534884            0.063988            19.764706   \n",
       "108              41       -0.223881            0.120939            25.181818   \n",
       "109               4        0.794872            0.107143            21.411765   \n",
       "110              36       -0.090909            0.138655            39.666667   \n",
       "\n",
       "     Percentage of Complex words  Fog Index  Avg Words Per Sentence  \\\n",
       "0                       0.451404  11.404804               28.060606   \n",
       "1                       0.395948  14.638379               36.200000   \n",
       "2                       0.468085  11.601520               28.535714   \n",
       "3                       0.377076   7.233184               17.705882   \n",
       "4                       0.421196   7.915847               19.368421   \n",
       "..                           ...        ...                     ...   \n",
       "106                     0.408313   9.252214               22.722222   \n",
       "107                     0.403274   8.067192               19.764706   \n",
       "108                     0.393502  10.230128               25.181818   \n",
       "109                     0.530220   8.776794               21.411765   \n",
       "110                     0.378151  16.017927               39.666667   \n",
       "\n",
       "     Complex word count  Word Count  \\\n",
       "0                   418         926   \n",
       "1                   215         543   \n",
       "2                   374         799   \n",
       "3                   227         602   \n",
       "4                   310         736   \n",
       "..                  ...         ...   \n",
       "106                 167         409   \n",
       "107                 271         672   \n",
       "108                 218         554   \n",
       "109                 193         364   \n",
       "110                 180         476   \n",
       "\n",
       "                                    Syllables per Word  Personal Pronouns  \\\n",
       "0    [5, 1, 1, 3, 1, 3, 2, 1, 3, 3, 2, 2, 3, 1, 3, ...                  0   \n",
       "1    [2, 1, 4, 2, 3, 3, 2, 1, 1, 4, 2, 2, 2, 2, 4, ...                  0   \n",
       "2    [5, 2, 3, 3, 2, 2, 3, 3, 2, 2, 4, 4, 3, 3, 4, ...                  0   \n",
       "3    [1, 1, 5, 4, 1, 4, 4, 4, 4, 6, 2, 4, 4, 1, 1, ...                  0   \n",
       "4    [2, 4, 3, 3, 3, 3, 1, 1, 4, 4, 3, 2, 1, 2, 2, ...                  1   \n",
       "..                                                 ...                ...   \n",
       "106  [4, 3, 3, 1, 4, 1, 3, 1, 4, 1, 3, 1, 2, 2, 1, ...                  0   \n",
       "107  [4, 3, 2, 1, 3, 3, 3, 1, 4, 5, 3, 1, 2, 3, 3, ...                  0   \n",
       "108  [2, 3, 2, 2, 3, 1, 1, 3, 2, 1, 3, 4, 4, 2, 4, ...                  0   \n",
       "109  [3, 4, 3, 2, 4, 3, 3, 2, 1, 2, 3, 3, 2, 1, 4, ...                  0   \n",
       "110  [1, 3, 2, 2, 1, 2, 3, 2, 1, 2, 1, 2, 1, 1, 2, ...                  0   \n",
       "\n",
       "     Average Word Length  \n",
       "0               7.989201  \n",
       "1               7.364641  \n",
       "2               7.968711  \n",
       "3               7.528239  \n",
       "4               7.701087  \n",
       "..                   ...  \n",
       "106             8.002445  \n",
       "107             7.552083  \n",
       "108             7.373646  \n",
       "109             8.343407  \n",
       "110             7.365546  \n",
       "\n",
       "[111 rows x 17 columns]"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "67a7d2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"Title\", \"Text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "f1466096",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\n",
    "    \"positive_score\": \"POSITIVE SCORE\",\n",
    "    \"negative_score\": \"NEGATIVE SCORE\",\n",
    "    \"polarity_score\": \"POLARITY SCORE\",\n",
    "    \"subjectivity_score\": \"SUBJECTIVITY SCORE\",\n",
    "    \"Avg Sentence Length\": \"AVG SENTENCE LENGTH\",\n",
    "    \"Percentage of Complex words\": \"PERCENTAGE OF COMPLEX WORDS\",\n",
    "    \"Fog Index\": \"FOG INDEX\",\n",
    "    \"Avg Words Per Sentence\": \"AVG NUMBER OF WORDS PER SENTENCE\",\n",
    "    \"Complex word count\": \"COMPLEX WORD COUNT\",\n",
    "    \"Word Count\": \"WORD COUNT\",\n",
    "    \"Syllables per Word\": \"SYLLABLE PER WORD\",\n",
    "    \"Personal Pronouns\": \"PERSONAL PRONOUNS\",\n",
    "    \"Average Word Length\": \"AVG WORD LENGTH\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "93067688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>POSITIVE SCORE</th>\n",
       "      <th>NEGATIVE SCORE</th>\n",
       "      <th>POLARITY SCORE</th>\n",
       "      <th>SUBJECTIVITY SCORE</th>\n",
       "      <th>AVG SENTENCE LENGTH</th>\n",
       "      <th>PERCENTAGE OF COMPLEX WORDS</th>\n",
       "      <th>FOG INDEX</th>\n",
       "      <th>AVG NUMBER OF WORDS PER SENTENCE</th>\n",
       "      <th>COMPLEX WORD COUNT</th>\n",
       "      <th>WORD COUNT</th>\n",
       "      <th>SYLLABLE PER WORD</th>\n",
       "      <th>PERSONAL PRONOUNS</th>\n",
       "      <th>AVG WORD LENGTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-in-healthc...</td>\n",
       "      <td>58</td>\n",
       "      <td>30</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.095032</td>\n",
       "      <td>28.060606</td>\n",
       "      <td>0.451404</td>\n",
       "      <td>11.404804</td>\n",
       "      <td>28.060606</td>\n",
       "      <td>418</td>\n",
       "      <td>926</td>\n",
       "      <td>[5, 1, 1, 3, 1, 3, 2, 1, 3, 3, 2, 2, 3, 1, 3, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>7.989201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>https://insights.blackcoffer.com/what-if-the-c...</td>\n",
       "      <td>55</td>\n",
       "      <td>35</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.165746</td>\n",
       "      <td>36.200000</td>\n",
       "      <td>0.395948</td>\n",
       "      <td>14.638379</td>\n",
       "      <td>36.200000</td>\n",
       "      <td>215</td>\n",
       "      <td>543</td>\n",
       "      <td>[2, 1, 4, 2, 3, 3, 2, 1, 1, 4, 2, 2, 2, 2, 4, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>7.364641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>https://insights.blackcoffer.com/what-jobs-wil...</td>\n",
       "      <td>64</td>\n",
       "      <td>34</td>\n",
       "      <td>0.306122</td>\n",
       "      <td>0.122653</td>\n",
       "      <td>28.535714</td>\n",
       "      <td>0.468085</td>\n",
       "      <td>11.601520</td>\n",
       "      <td>28.535714</td>\n",
       "      <td>374</td>\n",
       "      <td>799</td>\n",
       "      <td>[5, 2, 3, 3, 2, 2, 3, 3, 2, 2, 4, 4, 3, 3, 4, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>7.968711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>https://insights.blackcoffer.com/will-machine-...</td>\n",
       "      <td>59</td>\n",
       "      <td>21</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.132890</td>\n",
       "      <td>17.705882</td>\n",
       "      <td>0.377076</td>\n",
       "      <td>7.233184</td>\n",
       "      <td>17.705882</td>\n",
       "      <td>227</td>\n",
       "      <td>602</td>\n",
       "      <td>[1, 1, 5, 4, 1, 4, 4, 4, 4, 6, 2, 4, 4, 1, 1, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>7.528239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>https://insights.blackcoffer.com/will-ai-repla...</td>\n",
       "      <td>54</td>\n",
       "      <td>24</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.105978</td>\n",
       "      <td>19.368421</td>\n",
       "      <td>0.421196</td>\n",
       "      <td>7.915847</td>\n",
       "      <td>19.368421</td>\n",
       "      <td>310</td>\n",
       "      <td>736</td>\n",
       "      <td>[2, 4, 3, 3, 3, 3, 1, 1, 4, 4, 3, 2, 1, 2, 2, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>7.701087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>146</td>\n",
       "      <td>https://insights.blackcoffer.com/impact-of-cov...</td>\n",
       "      <td>20</td>\n",
       "      <td>25</td>\n",
       "      <td>-0.111111</td>\n",
       "      <td>0.110024</td>\n",
       "      <td>22.722222</td>\n",
       "      <td>0.408313</td>\n",
       "      <td>9.252214</td>\n",
       "      <td>22.722222</td>\n",
       "      <td>167</td>\n",
       "      <td>409</td>\n",
       "      <td>[4, 3, 3, 1, 4, 1, 3, 1, 4, 1, 3, 1, 2, 2, 1, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>8.002445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>147</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33</td>\n",
       "      <td>10</td>\n",
       "      <td>0.534884</td>\n",
       "      <td>0.063988</td>\n",
       "      <td>19.764706</td>\n",
       "      <td>0.403274</td>\n",
       "      <td>8.067192</td>\n",
       "      <td>19.764706</td>\n",
       "      <td>271</td>\n",
       "      <td>672</td>\n",
       "      <td>[4, 3, 2, 1, 3, 3, 3, 1, 4, 5, 3, 1, 2, 3, 3, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>7.552083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>148</td>\n",
       "      <td>https://insights.blackcoffer.com/blockchain-in...</td>\n",
       "      <td>26</td>\n",
       "      <td>41</td>\n",
       "      <td>-0.223881</td>\n",
       "      <td>0.120939</td>\n",
       "      <td>25.181818</td>\n",
       "      <td>0.393502</td>\n",
       "      <td>10.230128</td>\n",
       "      <td>25.181818</td>\n",
       "      <td>218</td>\n",
       "      <td>554</td>\n",
       "      <td>[2, 3, 2, 2, 3, 1, 1, 3, 2, 1, 3, 4, 4, 2, 4, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>7.373646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>149</td>\n",
       "      <td>https://insights.blackcoffer.com/blockchain-fo...</td>\n",
       "      <td>35</td>\n",
       "      <td>4</td>\n",
       "      <td>0.794872</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>21.411765</td>\n",
       "      <td>0.530220</td>\n",
       "      <td>8.776794</td>\n",
       "      <td>21.411765</td>\n",
       "      <td>193</td>\n",
       "      <td>364</td>\n",
       "      <td>[3, 4, 3, 2, 4, 3, 3, 2, 1, 2, 3, 3, 2, 1, 4, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>8.343407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>150</td>\n",
       "      <td>https://insights.blackcoffer.com/the-future-of...</td>\n",
       "      <td>30</td>\n",
       "      <td>36</td>\n",
       "      <td>-0.090909</td>\n",
       "      <td>0.138655</td>\n",
       "      <td>39.666667</td>\n",
       "      <td>0.378151</td>\n",
       "      <td>16.017927</td>\n",
       "      <td>39.666667</td>\n",
       "      <td>180</td>\n",
       "      <td>476</td>\n",
       "      <td>[1, 3, 2, 2, 1, 2, 3, 2, 1, 2, 1, 2, 1, 1, 2, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>7.365546</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>111 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     URL_ID                                                URL  \\\n",
       "0        37  https://insights.blackcoffer.com/ai-in-healthc...   \n",
       "1        38  https://insights.blackcoffer.com/what-if-the-c...   \n",
       "2        39  https://insights.blackcoffer.com/what-jobs-wil...   \n",
       "3        40  https://insights.blackcoffer.com/will-machine-...   \n",
       "4        41  https://insights.blackcoffer.com/will-ai-repla...   \n",
       "..      ...                                                ...   \n",
       "106     146  https://insights.blackcoffer.com/impact-of-cov...   \n",
       "107     147                                                NaN   \n",
       "108     148  https://insights.blackcoffer.com/blockchain-in...   \n",
       "109     149  https://insights.blackcoffer.com/blockchain-fo...   \n",
       "110     150  https://insights.blackcoffer.com/the-future-of...   \n",
       "\n",
       "     POSITIVE SCORE  NEGATIVE SCORE  POLARITY SCORE  SUBJECTIVITY SCORE  \\\n",
       "0                58              30        0.318182            0.095032   \n",
       "1                55              35        0.222222            0.165746   \n",
       "2                64              34        0.306122            0.122653   \n",
       "3                59              21        0.475000            0.132890   \n",
       "4                54              24        0.384615            0.105978   \n",
       "..              ...             ...             ...                 ...   \n",
       "106              20              25       -0.111111            0.110024   \n",
       "107              33              10        0.534884            0.063988   \n",
       "108              26              41       -0.223881            0.120939   \n",
       "109              35               4        0.794872            0.107143   \n",
       "110              30              36       -0.090909            0.138655   \n",
       "\n",
       "     AVG SENTENCE LENGTH  PERCENTAGE OF COMPLEX WORDS  FOG INDEX  \\\n",
       "0              28.060606                     0.451404  11.404804   \n",
       "1              36.200000                     0.395948  14.638379   \n",
       "2              28.535714                     0.468085  11.601520   \n",
       "3              17.705882                     0.377076   7.233184   \n",
       "4              19.368421                     0.421196   7.915847   \n",
       "..                   ...                          ...        ...   \n",
       "106            22.722222                     0.408313   9.252214   \n",
       "107            19.764706                     0.403274   8.067192   \n",
       "108            25.181818                     0.393502  10.230128   \n",
       "109            21.411765                     0.530220   8.776794   \n",
       "110            39.666667                     0.378151  16.017927   \n",
       "\n",
       "     AVG NUMBER OF WORDS PER SENTENCE  COMPLEX WORD COUNT  WORD COUNT  \\\n",
       "0                           28.060606                 418         926   \n",
       "1                           36.200000                 215         543   \n",
       "2                           28.535714                 374         799   \n",
       "3                           17.705882                 227         602   \n",
       "4                           19.368421                 310         736   \n",
       "..                                ...                 ...         ...   \n",
       "106                         22.722222                 167         409   \n",
       "107                         19.764706                 271         672   \n",
       "108                         25.181818                 218         554   \n",
       "109                         21.411765                 193         364   \n",
       "110                         39.666667                 180         476   \n",
       "\n",
       "                                     SYLLABLE PER WORD  PERSONAL PRONOUNS  \\\n",
       "0    [5, 1, 1, 3, 1, 3, 2, 1, 3, 3, 2, 2, 3, 1, 3, ...                  0   \n",
       "1    [2, 1, 4, 2, 3, 3, 2, 1, 1, 4, 2, 2, 2, 2, 4, ...                  0   \n",
       "2    [5, 2, 3, 3, 2, 2, 3, 3, 2, 2, 4, 4, 3, 3, 4, ...                  0   \n",
       "3    [1, 1, 5, 4, 1, 4, 4, 4, 4, 6, 2, 4, 4, 1, 1, ...                  0   \n",
       "4    [2, 4, 3, 3, 3, 3, 1, 1, 4, 4, 3, 2, 1, 2, 2, ...                  1   \n",
       "..                                                 ...                ...   \n",
       "106  [4, 3, 3, 1, 4, 1, 3, 1, 4, 1, 3, 1, 2, 2, 1, ...                  0   \n",
       "107  [4, 3, 2, 1, 3, 3, 3, 1, 4, 5, 3, 1, 2, 3, 3, ...                  0   \n",
       "108  [2, 3, 2, 2, 3, 1, 1, 3, 2, 1, 3, 4, 4, 2, 4, ...                  0   \n",
       "109  [3, 4, 3, 2, 4, 3, 3, 2, 1, 2, 3, 3, 2, 1, 4, ...                  0   \n",
       "110  [1, 3, 2, 2, 1, 2, 3, 2, 1, 2, 1, 2, 1, 1, 2, ...                  0   \n",
       "\n",
       "     AVG WORD LENGTH  \n",
       "0           7.989201  \n",
       "1           7.364641  \n",
       "2           7.968711  \n",
       "3           7.528239  \n",
       "4           7.701087  \n",
       "..               ...  \n",
       "106         8.002445  \n",
       "107         7.552083  \n",
       "108         7.373646  \n",
       "109         8.343407  \n",
       "110         7.365546  \n",
       "\n",
       "[111 rows x 15 columns]"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "18d177c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"Output.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3ac353",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
